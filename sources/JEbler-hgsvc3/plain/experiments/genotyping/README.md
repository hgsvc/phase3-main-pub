

# Genotyping

This contains the pipeline used to run the genotyping experiments for the HGSVC3 paper.
See the steps below to replicate the analysis.

## How to replicate the results

### Step 1: Downloading input files

Download Minigraph-Cactus VCF and GFA files:
```bat
wget -P inputs/ https://s3-us-west-2.amazonaws.com/human-pangenomics/pangenomes/scratch/2024_02_23_minigraph_cactus_hgsvc3_hprc/hgsvc3-hprc-2024-02-23-mc-chm13.gfa.gz
wget -P inputs/ https://s3-us-west-2.amazonaws.com/human-pangenomics/pangenomes/scratch/2024_02_23_minigraph_cactus_hgsvc3_hprc/hgsvc3-hprc-2024-02-23-mc-chm13.vcf.gz
```

Download CHM13 reference genome:

```bat
wget -P inputs/ https://s3-us-west-2.amazonaws.com/human-pangenomics/T2T/CHM13/assemblies/analysis_set/chm13v2.0.fa.gz
```

Download GRCh38 reference genome:

```bat
wget -P inputs/ http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/HGSVC2/technical/reference/20200513_hg38_NoALT/hg38.no_alt.fa.gz
gunzip inputs/hg38.no_alt.fa.gz
```

Download external genotyped sets:

* NYGC Illumina-based SV calls:
```bat
wget -P inputs/ https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20210124.SV_Illumina_Integration/1KGP_3202.gatksv_svtools_novelins.freeze_V3.wAF.vcf.gz
wget -p inputs/ https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20210124.SV_Illumina_Integration/1KGP_3202.gatksv_svtools_novelins.freeze_V3.wAF.vcf.gz.tbi
```
* HPRC PanGenie genotypes (filtered set)
```bat
wget -P inputs/ https://zenodo.org/records/6797328/files/all-samples_bi_all.vcf.gz?download=1
wget -P inputs/ https://zenodo.org/records/6797328/files/bi_all_filters.tsv.gz?download=1

gunzip inputs/bi_all_filters.tsv.gz

wget -P inputs/ https://zenodo.org/records/6797328/files/select_ids.py?download=1

zcat all-samples_bi_all.vcf.gz | python3 inputs/select_ids.py inputs/bi_all_filters.tsv filtered | bgzip -c > inputs/all-samples_bi_filtered.vcf.gz

tabix -p vcf inputs/all-samples_bi_filtered.vcf.gz
```

Furthermore, 1000G Illumina reads for all 3,202 samples and additional panel samples need to be provided (one file per sample). Paths to these files need to be provided in the `` inputs/1kg-reads-updated.tsv `` (this file needs to be edited).
Reads were obtained from the locations below and one FASTA file per sample was generated by concatenating individual FASTA/FASTQ files into a single file.

* **3,202 1kg samples:** http://ftp.sra.ebi.ac.uk/vol1/fastq/
* **NA24385:** https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/NIST_Illumina_2x250bps/reads/
* **NA21309:** https://s3-us-west-2.amazonaws.com/human-pangenomics/index.html?prefix=working/HPRC_PLUS/NA21309/raw_data/Illumina/child/
* **HG01123, HG02486, HG02559:** https://s3-us-west-2.amazonaws.com/human-pangenomics/index.html?prefix=submissions/30E441F3-6820-4BF6-BCF4-E64D56C8D6A4--TRUSEQ/

### Step 2: run snakemake pipeline
Dependencies:
* snakemake
* singularity
* conda

```bat
snakemake -j <nr_cores> --use-conda
```

* The filtered genotypes will be written to: `` results/benchmarking-pipeline/population-typing/MC-hgsvc3-hprc-chm13/pangenie-108/full/merged-vcfs/filtered/all-samples_bi_all_lenient.vcf.gz ``   

* Input panel for PanGenie will be written to: `` results/prepare-vcf-MC/vcf/MC-hgsvc3-hprc-chm13/MC-hgsvc3-hprc-chm13_filtered_ids.vcf.gz ``   
* Input panel deconstructed (useful for convertion to biallelic): `` results/prepare-vcf-MC/vcf/MC-hgsvc3-hprc-chm13/MC-hgsvc3-hprc-chm13_filtered_ids_biallelic.vcf.gz ``
