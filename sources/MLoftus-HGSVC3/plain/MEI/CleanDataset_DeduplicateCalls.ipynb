{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80cee299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import json\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dca91d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14210\n"
     ]
    }
   ],
   "source": [
    "hg38Merged = pd.read_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/old_wScott/hg38/hg38_MergedCallSet_PASSED_06-18-2024_Clean.csv').set_index(\"Unnamed: 0\")\n",
    "print(len(hg38Merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32b4dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14404\n"
     ]
    }
   ],
   "source": [
    "#Read In the Merged hg38 Set and Filter out Arthurs removed calls\n",
    "t2tMerged = pd.read_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/old_wScott/t2t/t2t_MergedCallSet_PASSED_06-18-2024_Clean.csv').set_index(\"Unnamed: 0\")\n",
    "print(len(t2tMerged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc9e9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scottshg38Calls=[x for x in hg38Merged[(hg38Merged['Caller_Count']==1) & (hg38Merged['Devine_Lab']==1)].index]\n",
    "scottsT2TCalls=[x for x in t2tMerged[(t2tMerged['Caller_Count']==1) & (t2tMerged['Devine_Lab']==1)].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c684af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "print(len(scottshg38Calls))\n",
    "print(len(scottsT2TCalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c30a4c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg38Cleaned = hg38Merged.loc[[x for x in hg38Merged.index if x not in scottshg38Calls]].drop(columns=['Devine_Lab', 'Devine_Lab_INFO']).copy()\n",
    "t2tCleaned = t2tMerged.loc[[x for x in t2tMerged.index if x not in scottsT2TCalls]].drop(columns=['Devine_Lab', 'Devine_Lab_INFO']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "791495a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg38Cleaned['Caller_Count'] = [int(x)+int(y) for x,y in zip(hg38Cleaned['Konkel_Lab'],hg38Cleaned['PALMER'])]\n",
    "t2tCleaned['Caller_Count'] = [int(x)+int(y) for x,y in zip(t2tCleaned['Konkel_Lab'],t2tCleaned['PALMER'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8772b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hg38Cleaned.to_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/hg38_allCalls_07-24-2024.csv')\n",
    "#t2tCleaned.to_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/hs1_allCalls_07-24-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4342820",
   "metadata": {},
   "outputs": [],
   "source": [
    "arthurhg38 = hg38Cleaned[(hg38Cleaned['Caller_Count']==1) & (hg38Cleaned['PALMER']==1)].copy()\n",
    "arthurhs1 = t2tCleaned[(t2tCleaned['Caller_Count']==1) & (t2tCleaned['PALMER']==1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96af5175",
   "metadata": {},
   "outputs": [],
   "source": [
    "konkelhg38 = hg38Cleaned[(hg38Cleaned['Caller_Count']==1) & (hg38Cleaned['Konkel_Lab']==1)].copy()\n",
    "konkelhs1 = t2tCleaned[(t2tCleaned['Caller_Count']==1) & (t2tCleaned['Konkel_Lab']==1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c98912bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = '/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hg38/'\n",
    "#with open(directory+'arthurhg38_Sequences.fasta','a+') as file:\n",
    "#    for row in arthurhg38.index:\n",
    "#        file.write(\">\"+str(row)+'\\n')\n",
    "#        file.write(str(arthurhg38.at[row,'ALT'])+\"\\n\")\n",
    "#file.close()\n",
    "\n",
    "#directory = '/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hs1/'\n",
    "#with open(directory+'arthurhs1_Sequences.fasta','a+') as file:\n",
    "#    for row in arthurhs1.index:\n",
    "#        file.write(\">\"+str(row)+'\\n')\n",
    "#        file.write(str(arthurhs1.at[row,'ALT'])+\"\\n\")\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "578f3fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = '/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/KonkelSequences/hg38/'\n",
    "#with open(directory+'konkelhg38_Sequences.fasta','a+') as file:\n",
    "#    for row in konkelhg38.index:\n",
    "#        file.write(\">\"+str(row)+'\\n')\n",
    "#        file.write(str(konkelhg38.at[row,'ALT'])+\"\\n\")\n",
    "#file.close()\n",
    "\n",
    "#directory = '/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/KonkelSequences/hs1/'\n",
    "#with open(directory+'konkelhs1_Sequences.fasta','a+') as file:\n",
    "#    for row in konkelhs1.index:\n",
    "#        file.write(\">\"+str(row)+'\\n')\n",
    "#        file.write(str(konkelhs1.at[row,'ALT'])+\"\\n\")\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422a567",
   "metadata": {},
   "source": [
    "## Filter out the HERVs that need to be removed manually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4536fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg38Cleaned = pd.read_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/hg38_hgsvc3_finalManuscript.csv').set_index(\"ID\")\n",
    "t2tCleaned=pd.read_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/hs1_hgsvc3_finalManuscript.csv').set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6461e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg38bad = ['MEI_14010-chr8-145027990']\n",
    "t2tbad = ['MEI_13634-chr8-11959656', 'MEI_13636-chr8-12500180']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f75240df",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg382 = hg38Cleaned.loc[[x for x in hg38Cleaned.index if x not in hg38bad]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdb56b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2t2 = t2tCleaned.loc[[x for x in t2tCleaned.index if x not in t2tbad]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65767473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13082\n",
      "13298\n"
     ]
    }
   ],
   "source": [
    "print(len(hg382))\n",
    "print(len(t2t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e909be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hg382.to_csv(\"/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/GRCh38_hgsvc3_PublicationSet.csv\")\n",
    "#t2t2.to_csv(\"/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/t2tCHM13_hgsvc3_PublicationSet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10755b3b",
   "metadata": {},
   "source": [
    "## Deduplicate PAV \"Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7281366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg38 = pd.read_csv(\"/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/GRCh38_hgsvc3_PublicationSet.csv\").set_index(\"ID\")\n",
    "t2t2=pd.read_csv(\"/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/t2tCHM13_hgsvc3_PublicationSet.csv\").set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c7624915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr9_129033138\n",
      "{'SINE/Alu', 'Retroposon/SVA'}\n",
      "HUH3\n"
     ]
    }
   ],
   "source": [
    "unique = []\n",
    "duplicated=[]\n",
    "allCalls = [str(x)+\"_\"+str(y) for x,y in zip(hg38['CHROM'], hg38['POS'])]\n",
    "dupsDict= collections.Counter(allCalls)\n",
    "for call in hg38.index:\n",
    "    chromPos = str(hg38.at[call,'CHROM'])+\"_\"+str(hg38.at[call,'POS'])\n",
    "    if dupsDict[chromPos]==1:\n",
    "        unique.append(call)\n",
    "    else:\n",
    "        duplicated.append(call)\n",
    "uniquehg38 = hg38.loc[unique].copy()\n",
    "tempDupDF = hg38.loc[duplicated].copy()\n",
    "tempDupDF['chromLoc']=[str(x)+\"_\"+str(y) for x,y in zip(tempDupDF['CHROM'], tempDupDF['POS'])]\n",
    "sampleDict={x:'temp' for x in ['HG00096', 'HG00171', 'HG00268', 'HG00358', 'HG00512', 'HG00513',\n",
    "       'HG00514', 'HG00731', 'HG00732', 'HG00733', 'HG00864', 'HG01114',\n",
    "       'HG01352', 'HG01457', 'HG01505', 'HG01573', 'HG01596', 'HG01890',\n",
    "       'HG02011', 'HG02018', 'HG02059', 'HG02106', 'HG02282', 'HG02492',\n",
    "       'HG02554', 'HG02587', 'HG02666', 'HG02769', 'HG02818', 'HG02953',\n",
    "       'HG03009', 'HG03065', 'HG03248', 'HG03371', 'HG03452', 'HG03456',\n",
    "       'HG03520', 'HG03683', 'HG03732', 'HG03807', 'HG04036', 'HG04217',\n",
    "       'NA12329', 'NA18534', 'NA18939', 'NA18989', 'NA19036', 'NA19129',\n",
    "       'NA19238', 'NA19239', 'NA19240', 'NA19317', 'NA19331', 'NA19347',\n",
    "       'NA19384', 'NA19434', 'NA19650', 'NA19705', 'NA19836', 'NA19983',\n",
    "       'NA20355', 'NA20509', 'NA20847', 'NA21487', 'NA24385']}\n",
    "\n",
    "dedupDict={}\n",
    "additionalCops=[]\n",
    "for dupPosition in set(tempDupDF['chromLoc']):\n",
    "        \n",
    "    dedupDict[dupPosition]={'Chosen':'temp', 'Duplications':[]}\n",
    "    testDF = tempDupDF[tempDupDF['chromLoc']==dupPosition].copy()\n",
    "    \n",
    "    #See if both callers are having hits\n",
    "    arthurCount=0\n",
    "    limeCount=0\n",
    "    PALMERrow='temp'\n",
    "    PALMERsinglerow='temp'\n",
    "    for row in testDF.index:\n",
    "        \n",
    "        if int(testDF.at[row,'L1ME-AID_Lab'])==1 and int(testDF.at[row,'PALMER'])==1:\n",
    "            limeCount+=1\n",
    "            arthurCount+=1\n",
    "            PALMERrow=row\n",
    "            \n",
    "        elif int(testDF.at[row,'L1ME-AID_Lab'])==0 and int(testDF.at[row,'PALMER'])==1:\n",
    "            arthurCount+=1\n",
    "            PALMERsinglerow=row\n",
    "        \n",
    "        elif int(testDF.at[row,'L1ME-AID_Lab'])==1 and int(testDF.at[row,'PALMER'])==0:\n",
    "            limeCount+=1\n",
    "        \n",
    "        else:\n",
    "            print('HUH')\n",
    "            \n",
    "    #if PALMERrow !='temp' and PALMERsinglerow!='temp':\n",
    "    #    print(dupPosition)\n",
    "    #else:\n",
    "    #    pass\n",
    "    \n",
    "    #If no hits were called by PALMER then worry about intra-PAV duplications\n",
    "    if arthurCount == 0 and len(set(testDF['TE_Designation']))==1:\n",
    "        \n",
    "        \n",
    "        largest='temp'\n",
    "        largestLength=0\n",
    "        for row in testDF.index:\n",
    "            if int(row.split(\"-\")[-1])>largestLength:\n",
    "                largestLength = int(row.split(\"-\")[-1])\n",
    "                largest = row\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        dedupDict[dupPosition]['Chosen']=largest\n",
    "        dedupDict[dupPosition]['Duplications']=[y for y in testDF.index if y !=largest]\n",
    "        \n",
    "        for sample in sampleDict.keys():\n",
    "            pos1='0'\n",
    "            pos2='0'\n",
    "            pos3='0'\n",
    "            \n",
    "            for geno in testDF[sample]:\n",
    "                if str(geno.split(\"|\")[0]) != '0':\n",
    "                    pos1 =str(geno.split(\"|\")[0])\n",
    "                    \n",
    "                if str(geno.split(\"|\")[1]) != '0':\n",
    "                    pos2 =str(geno.split(\"|\")[1])\n",
    "                    \n",
    "                if str(geno.split(\"|\")[2]) != '0':\n",
    "                    pos3 =str(geno.split(\"|\")[2])\n",
    "                    \n",
    "                    \n",
    "            newString = str(pos1+\"|\"+pos2+\"|\"+pos3)\n",
    "            tempDupDF.at[largest,sample]=newString\n",
    "             \n",
    "        \n",
    "    #Else if hits were also called by PALMER\n",
    "    elif arthurCount !=0 and len(set(testDF['TE_Designation']))==1:\n",
    "        \n",
    "        if PALMERrow !='temp':\n",
    "            largest=PALMERrow\n",
    "            largestLength=0\n",
    "            dedupDict[dupPosition]['Chosen']=largest\n",
    "            dedupDict[dupPosition]['Duplications']=[y for y in testDF.index if y !=largest]\n",
    "            \n",
    "            # Merge genotyping\n",
    "            for sample in sampleDict.keys():\n",
    "                pos1='0'\n",
    "                pos2='0'\n",
    "                pos3='0'\n",
    "\n",
    "                for row in testDF.index:\n",
    "                    if 'MEI' in str(row):\n",
    "                        geno = str(testDF.at[row,sample])\n",
    "                        if str(geno.split(\"|\")[0]) != '0':\n",
    "                            pos1 =str(geno.split(\"|\")[0])\n",
    "\n",
    "                        if str(geno.split(\"|\")[1]) != '0':\n",
    "                            pos2 =str(geno.split(\"|\")[1])\n",
    "\n",
    "                    else:\n",
    "                        geno = str(testDF.at[row,sample])\n",
    "                        if str(geno.split(\"|\")[0]) != '0':\n",
    "                            pos1 =str(geno.split(\"|\")[0])\n",
    "\n",
    "                        if str(geno.split(\"|\")[1]) != '0':\n",
    "                            pos2 =str(geno.split(\"|\")[1])\n",
    "\n",
    "                        if str(geno.split(\"|\")[2]) != '0':\n",
    "                            pos3 =str(geno.split(\"|\")[2])\n",
    "\n",
    "\n",
    "                newString = str(pos1+\"|\"+pos2+\"|\"+pos3)\n",
    "                tempDupDF.at[largest,sample]=newString\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            largest='temp'\n",
    "            largestLength=0\n",
    "            for row in testDF.index:\n",
    "                if len(testDF.at[row,'ALT'])>largestLength:\n",
    "                    largestLength = len(testDF.at[row,'ALT'])\n",
    "                    largest = row\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "            if largest == PALMERsinglerow:\n",
    "                reverseFlag=1\n",
    "            else:\n",
    "                reverseFlag=0\n",
    "\n",
    "\n",
    "            dedupDict[dupPosition]['Chosen']=largest\n",
    "            dedupDict[dupPosition]['Duplications']=[y for y in testDF.index if y !=largest]\n",
    "            \n",
    "            # Merge genotyping\n",
    "            for sample in sampleDict.keys():\n",
    "                pos1='0'\n",
    "                pos2='0'\n",
    "                pos3='0'\n",
    "\n",
    "                for row in testDF.index:\n",
    "                    if 'MEI' in str(row):\n",
    "                        geno = str(testDF.at[row,sample])\n",
    "                        if str(geno.split(\"|\")[0]) != '0':\n",
    "                            pos1 =str(geno.split(\"|\")[0])\n",
    "\n",
    "                        if str(geno.split(\"|\")[1]) != '0':\n",
    "                            pos2 =str(geno.split(\"|\")[1])\n",
    "\n",
    "                    else:\n",
    "                        geno = str(testDF.at[row,sample])\n",
    "                        if str(geno.split(\"|\")[0]) != '0':\n",
    "                            pos1 =str(geno.split(\"|\")[0])\n",
    "\n",
    "                        if str(geno.split(\"|\")[1]) != '0':\n",
    "                            pos2 =str(geno.split(\"|\")[1])\n",
    "\n",
    "                        if str(geno.split(\"|\")[2]) != '0':\n",
    "                            pos3 =str(geno.split(\"|\")[2])\n",
    "\n",
    "\n",
    "                newString = str(pos1+\"|\"+pos2+\"|\"+pos3)\n",
    "                tempDupDF.at[largest,sample]=newString\n",
    "            \n",
    "            \n",
    "            if reverseFlag == 0:\n",
    "                tempDupDF.at[largest,'Caller_Count']=2\n",
    "                tempDupDF.at[largest,'PALMER']=1\n",
    "                tempDupDF.at[largest,'PALMER_INFO']=tempDupDF.at[PALMERsinglerow,'PALMER_INFO']\n",
    "                tempDupDF.at[largest,'L1ME-AID_Lab']=1\n",
    "                \n",
    "            else:\n",
    "                singleHit = dedupDict[dupPosition]['Duplications'][0]\n",
    "                \n",
    "                tempDupDF.at[largest,'Caller_Count']=2\n",
    "                tempDupDF.at[largest,'PALMER']=1\n",
    "                tempDupDF.at[largest,'L1ME-AID_Lab']=1\n",
    "                tempDupDF.at[largest,'L1ME-AID_INFO']=tempDupDF.at[singleHit,'L1ME-AID_INFO']\n",
    "        \n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(dupPosition)\n",
    "        print(set(testDF['TE_Designation']))\n",
    "        print(\"HUH3\") \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "tempDupDF['MergedCalls']='NONE'\n",
    "for row in tempDupDF.index:\n",
    "    for element in dedupDict.keys():\n",
    "        if dedupDict[element]['Chosen'] ==  row:\n",
    "            tempDupDF.at[row,'MergedCalls'] = dedupDict[element]['Duplications']\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "chosenRows=[]\n",
    "for x in dedupDict.keys():\n",
    "    for y in dedupDict[x]['Duplications']:\n",
    "        chosenRows.append(y)\n",
    "        \n",
    "deduplicatedDF = tempDupDF.loc[[x for x in tempDupDF.index if x not in chosenRows and x not in additionalCops]].copy()\n",
    "uniquehg38['chromLoc']='NONE'\n",
    "uniquehg38['MergedCalls']='NONE'\n",
    "concatList=[uniquehg38,deduplicatedDF]\n",
    "putBackDF = pd.concat(concatList)\n",
    "putBackDF.drop(columns=['chromLoc'], inplace=True)\n",
    "putBackDF2 = putBackDF.reset_index().copy()\n",
    "testRows=[]\n",
    "for row in putBackDF2.index:\n",
    "    originalID = str(putBackDF2.at[row,'ID'])\n",
    "    if 'MEI' in originalID and putBackDF2.at[row,'MergedCalls']!='NONE':\n",
    "        testRows.append(row)\n",
    "        \n",
    "        pavName = putBackDF2.at[row,'MergedCalls'][0]\n",
    "\n",
    "        putBackDF2.at[row,'ID']=pavName\n",
    "        putBackDF2.at[row,'ALT']=hg38.at[pavName,'ALT']\n",
    "\n",
    "        putBackDF2.at[row,'MergedCalls']='temp'\n",
    "        putBackDF2.at[row,'MergedCalls']=[originalID]\n",
    "\n",
    "\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "putBackDF2.set_index(\"ID\", inplace=True)\n",
    "finalhg38Demerged = putBackDF2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2c1dcc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr9_141236607\n",
      "{'SINE/Alu', 'Retroposon/SVA'}\n",
      "HUH3\n"
     ]
    }
   ],
   "source": [
    "unique = []\n",
    "duplicated=[]\n",
    "allCalls = [str(x)+\"_\"+str(y) for x,y in zip(t2t2['CHROM'], t2t2['POS'])]\n",
    "dupsDict= collections.Counter(allCalls)\n",
    "for call in t2t2.index:\n",
    "    chromPos = str(t2t2.at[call,'CHROM'])+\"_\"+str(t2t2.at[call,'POS'])\n",
    "    if dupsDict[chromPos]==1:\n",
    "        unique.append(call)\n",
    "    else:\n",
    "        duplicated.append(call)\n",
    "uniquet2t2 = t2t2.loc[unique].copy()\n",
    "tempDupDF = t2t2.loc[duplicated].copy()\n",
    "tempDupDF['chromLoc']=[str(x)+\"_\"+str(y) for x,y in zip(tempDupDF['CHROM'], tempDupDF['POS'])]\n",
    "sampleDict={x:'temp' for x in ['HG00096', 'HG00171', 'HG00268', 'HG00358', 'HG00512', 'HG00513',\n",
    "       'HG00514', 'HG00731', 'HG00732', 'HG00733', 'HG00864', 'HG01114',\n",
    "       'HG01352', 'HG01457', 'HG01505', 'HG01573', 'HG01596', 'HG01890',\n",
    "       'HG02011', 'HG02018', 'HG02059', 'HG02106', 'HG02282', 'HG02492',\n",
    "       'HG02554', 'HG02587', 'HG02666', 'HG02769', 'HG02818', 'HG02953',\n",
    "       'HG03009', 'HG03065', 'HG03248', 'HG03371', 'HG03452', 'HG03456',\n",
    "       'HG03520', 'HG03683', 'HG03732', 'HG03807', 'HG04036', 'HG04217',\n",
    "       'NA12329', 'NA18534', 'NA18939', 'NA18989', 'NA19036', 'NA19129',\n",
    "       'NA19238', 'NA19239', 'NA19240', 'NA19317', 'NA19331', 'NA19347',\n",
    "       'NA19384', 'NA19434', 'NA19650', 'NA19705', 'NA19836', 'NA19983',\n",
    "       'NA20355', 'NA20509', 'NA20847', 'NA21487', 'NA24385']}\n",
    "dedupDict={}\n",
    "additionalCops=[]\n",
    "for dupPosition in set(tempDupDF['chromLoc']):\n",
    "        \n",
    "    dedupDict[dupPosition]={'Chosen':'temp', 'Duplications':[]}\n",
    "    testDF = tempDupDF[tempDupDF['chromLoc']==dupPosition].copy()\n",
    "    \n",
    "    #See if both callers are having hits\n",
    "    arthurCount=0\n",
    "    limeCount=0\n",
    "    PALMERrow='temp'\n",
    "    PALMERsinglerow='temp'\n",
    "    for row in testDF.index:\n",
    "        \n",
    "        if int(testDF.at[row,'L1ME-AID_Lab'])==1 and int(testDF.at[row,'PALMER'])==1:\n",
    "            limeCount+=1\n",
    "            arthurCount+=1\n",
    "            PALMERrow=row\n",
    "            \n",
    "        elif int(testDF.at[row,'L1ME-AID_Lab'])==0 and int(testDF.at[row,'PALMER'])==1:\n",
    "            arthurCount+=1\n",
    "            PALMERsinglerow=row\n",
    "        \n",
    "        elif int(testDF.at[row,'L1ME-AID_Lab'])==1 and int(testDF.at[row,'PALMER'])==0:\n",
    "            limeCount+=1\n",
    "        \n",
    "        else:\n",
    "            print('HUH')\n",
    "            \n",
    "    #if PALMERrow !='temp' and PALMERsinglerow!='temp':\n",
    "    #    print(dupPosition)\n",
    "    #else:\n",
    "    #    pass\n",
    "    \n",
    "    #If no hits were called by PALMER then worry about intra-PAV duplications\n",
    "    if arthurCount == 0 and len(set(testDF['TE_Designation']))==1:\n",
    "        \n",
    "        \n",
    "        largest='temp'\n",
    "        largestLength=0\n",
    "        for row in testDF.index:\n",
    "            if int(row.split(\"-\")[-1])>largestLength:\n",
    "                largestLength = int(row.split(\"-\")[-1])\n",
    "                largest = row\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        dedupDict[dupPosition]['Chosen']=largest\n",
    "        dedupDict[dupPosition]['Duplications']=[y for y in testDF.index if y !=largest]\n",
    "        \n",
    "        for sample in sampleDict.keys():\n",
    "            pos1='0'\n",
    "            pos2='0'\n",
    "            pos3='0'\n",
    "            \n",
    "            for geno in testDF[sample]:\n",
    "                if str(geno.split(\"|\")[0]) != '0':\n",
    "                    pos1 =str(geno.split(\"|\")[0])\n",
    "                    \n",
    "                if str(geno.split(\"|\")[1]) != '0':\n",
    "                    pos2 =str(geno.split(\"|\")[1])\n",
    "                    \n",
    "                if str(geno.split(\"|\")[2]) != '0':\n",
    "                    pos3 =str(geno.split(\"|\")[2])\n",
    "                    \n",
    "                    \n",
    "            newString = str(pos1+\"|\"+pos2+\"|\"+pos3)\n",
    "            tempDupDF.at[largest,sample]=newString\n",
    "             \n",
    "        \n",
    "    #Else if hits were also called by PALMER\n",
    "    elif arthurCount !=0 and len(set(testDF['TE_Designation']))==1:\n",
    "        \n",
    "        if PALMERrow !='temp':\n",
    "            largest=PALMERrow\n",
    "            largestLength=0\n",
    "            dedupDict[dupPosition]['Chosen']=largest\n",
    "            dedupDict[dupPosition]['Duplications']=[y for y in testDF.index if y !=largest]\n",
    "            \n",
    "            # Merge genotyping\n",
    "            for sample in sampleDict.keys():\n",
    "                pos1='0'\n",
    "                pos2='0'\n",
    "                pos3='0'\n",
    "\n",
    "                for row in testDF.index:\n",
    "                    if 'MEI' in str(row):\n",
    "                        geno = str(testDF.at[row,sample])\n",
    "                        if str(geno.split(\"|\")[0]) != '0':\n",
    "                            pos1 =str(geno.split(\"|\")[0])\n",
    "\n",
    "                        if str(geno.split(\"|\")[1]) != '0':\n",
    "                            pos2 =str(geno.split(\"|\")[1])\n",
    "\n",
    "                    else:\n",
    "                        geno = str(testDF.at[row,sample])\n",
    "                        if str(geno.split(\"|\")[0]) != '0':\n",
    "                            pos1 =str(geno.split(\"|\")[0])\n",
    "\n",
    "                        if str(geno.split(\"|\")[1]) != '0':\n",
    "                            pos2 =str(geno.split(\"|\")[1])\n",
    "\n",
    "                        if str(geno.split(\"|\")[2]) != '0':\n",
    "                            pos3 =str(geno.split(\"|\")[2])\n",
    "\n",
    "\n",
    "                newString = str(pos1+\"|\"+pos2+\"|\"+pos3)\n",
    "                tempDupDF.at[largest,sample]=newString\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            largest='temp'\n",
    "            largestLength=0\n",
    "            for row in testDF.index:\n",
    "                if len(testDF.at[row,'ALT'])>largestLength:\n",
    "                    largestLength = len(testDF.at[row,'ALT'])\n",
    "                    largest = row\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "            if largest == PALMERsinglerow:\n",
    "                reverseFlag=1\n",
    "            else:\n",
    "                reverseFlag=0\n",
    "\n",
    "\n",
    "            dedupDict[dupPosition]['Chosen']=largest\n",
    "            dedupDict[dupPosition]['Duplications']=[y for y in testDF.index if y !=largest]\n",
    "            \n",
    "            # Merge genotyping\n",
    "            for sample in sampleDict.keys():\n",
    "                pos1='0'\n",
    "                pos2='0'\n",
    "                pos3='0'\n",
    "\n",
    "                for row in testDF.index:\n",
    "                    if 'MEI' in str(row):\n",
    "                        geno = str(testDF.at[row,sample])\n",
    "                        if str(geno.split(\"|\")[0]) != '0':\n",
    "                            pos1 =str(geno.split(\"|\")[0])\n",
    "\n",
    "                        if str(geno.split(\"|\")[1]) != '0':\n",
    "                            pos2 =str(geno.split(\"|\")[1])\n",
    "\n",
    "                    else:\n",
    "                        geno = str(testDF.at[row,sample])\n",
    "                        if str(geno.split(\"|\")[0]) != '0':\n",
    "                            pos1 =str(geno.split(\"|\")[0])\n",
    "\n",
    "                        if str(geno.split(\"|\")[1]) != '0':\n",
    "                            pos2 =str(geno.split(\"|\")[1])\n",
    "\n",
    "                        if str(geno.split(\"|\")[2]) != '0':\n",
    "                            pos3 =str(geno.split(\"|\")[2])\n",
    "\n",
    "\n",
    "                newString = str(pos1+\"|\"+pos2+\"|\"+pos3)\n",
    "                tempDupDF.at[largest,sample]=newString\n",
    "            \n",
    "            \n",
    "            if reverseFlag == 0:\n",
    "                tempDupDF.at[largest,'Caller_Count']=2\n",
    "                tempDupDF.at[largest,'PALMER']=1\n",
    "                tempDupDF.at[largest,'PALMER_INFO']=tempDupDF.at[PALMERsinglerow,'PALMER_INFO']\n",
    "                tempDupDF.at[largest,'L1ME-AID_Lab']=1\n",
    "                \n",
    "            else:\n",
    "                singleHit = dedupDict[dupPosition]['Duplications'][0]\n",
    "                \n",
    "                tempDupDF.at[largest,'Caller_Count']=2\n",
    "                tempDupDF.at[largest,'PALMER']=1\n",
    "                tempDupDF.at[largest,'L1ME-AID_Lab']=1\n",
    "                tempDupDF.at[largest,'L1ME-AID_INFO']=tempDupDF.at[singleHit,'L1ME-AID_INFO']\n",
    "        \n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(dupPosition)\n",
    "        print(set(testDF['TE_Designation']))\n",
    "        print(\"HUH3\") \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "tempDupDF['MergedCalls']='NONE'\n",
    "for row in tempDupDF.index:\n",
    "    for element in dedupDict.keys():\n",
    "        if dedupDict[element]['Chosen'] ==  row:\n",
    "            tempDupDF.at[row,'MergedCalls'] = dedupDict[element]['Duplications']\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "chosenRows=[]\n",
    "for x in dedupDict.keys():\n",
    "    for y in dedupDict[x]['Duplications']:\n",
    "        chosenRows.append(y)\n",
    "        \n",
    "deduplicatedDF = tempDupDF.loc[[x for x in tempDupDF.index if x not in chosenRows and x not in additionalCops]].copy()\n",
    "uniquet2t2['chromLoc']='NONE'\n",
    "uniquet2t2['MergedCalls']='NONE'\n",
    "concatList=[uniquet2t2,deduplicatedDF]\n",
    "putBackDF = pd.concat(concatList)\n",
    "putBackDF.drop(columns=['chromLoc'], inplace=True)\n",
    "putBackDF2 = putBackDF.reset_index().copy()\n",
    "testRows=[]\n",
    "for row in putBackDF2.index:\n",
    "    originalID = str(putBackDF2.at[row,'ID'])\n",
    "    if 'MEI' in originalID and putBackDF2.at[row,'MergedCalls']!='NONE':\n",
    "        testRows.append(row)\n",
    "        \n",
    "        pavName = putBackDF2.at[row,'MergedCalls'][0]\n",
    "\n",
    "        putBackDF2.at[row,'ID']=pavName\n",
    "        putBackDF2.at[row,'ALT']=t2t2.at[pavName,'ALT']\n",
    "\n",
    "        putBackDF2.at[row,'MergedCalls']='temp'\n",
    "        putBackDF2.at[row,'MergedCalls']=[originalID]\n",
    "\n",
    "\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "putBackDF2.set_index(\"ID\", inplace=True)\n",
    "finalT2TDemerged = putBackDF2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2f5b1bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13216"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finalT2TDemerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8c3a47ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'SINE/Alu': 10689, 'LINE/L1': 1718, 'Retroposon/SVA': 803, 'HERVK': 5, 'snRNA': 1})\n"
     ]
    }
   ],
   "source": [
    "print(collections.Counter(finalT2TDemerged['TE_Designation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ee630795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'SINE/Alu': 9948, 'LINE/L1': 1416, 'Retroposon/SVA': 615})\n"
     ]
    }
   ],
   "source": [
    "print(collections.Counter(finalT2TDemerged[finalT2TDemerged['Caller_Count']>1]['TE_Designation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4a5bc3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3974399661483128"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13210/9453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "71710453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11979"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9948+1416+615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3b0da229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9064013317191283"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11979/13216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dba731bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11960.0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23920/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fba91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=9453 MEIs; Alu: 7738, L1: 1775, and SVA: 540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "52c30eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3745900772241617"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12994/9453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a796558d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'SINE/Alu': 10522, 'LINE/L1': 1702, 'Retroposon/SVA': 770, 'HERVK': 6, 'snRNA': 1})\n"
     ]
    }
   ],
   "source": [
    "print(collections.Counter(finalhg38Demerged['TE_Designation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f7106cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13001"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finalhg38Demerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "61619b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'SINE/Alu': 9932, 'LINE/L1': 1404, 'Retroposon/SVA': 605})\n"
     ]
    }
   ],
   "source": [
    "print(collections.Counter(finalhg38Demerged[finalhg38Demerged['Caller_Count']>1]['TE_Designation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "37df2850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11941"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9932+1404+605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8f08fd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9184678101684486"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11941/13001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6d929966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalhg38Demerged.to_csv(\"/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/GRCh38_hgsvc3_PublicationSet_Final.csv\")\n",
    "#finalT2TDemerged.to_csv(\"/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/t2tCHM13_hgsvc3_PublicationSet_Final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
