{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f167902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import json\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from Bio.Seq import Seq\n",
    "import more_itertools as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95f73cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sequence(sequence, subsequence):\n",
    "    positions = []\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = sequence.find(subsequence, start)\n",
    "        if start == -1:\n",
    "            break\n",
    "        positions.append(start)\n",
    "        start += 1\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa59d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orientationFinder(df):\n",
    "    df2 = df.copy()\n",
    "    df2['Orientation']='NONE'\n",
    "    for row in df2.index:\n",
    "        if df2.at[row,'TE_Hits'] == 'NONE':\n",
    "            continue\n",
    "        else:\n",
    "            elementAnnotation = str(df2.at[row,'Element_Annotation'])\n",
    "            sense=0\n",
    "            antisense=0\n",
    "            hitList = ast.literal_eval(str(df2.at[row,'TE_Hits']))\n",
    "            for hit in hitList:\n",
    "                if str(hit.split()[9]) == elementAnnotation:\n",
    "                    if str(hit.split()[8])=='+':\n",
    "                        sense+=1\n",
    "                    else:\n",
    "                        antisense+=1\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            if sense>0 and antisense ==0:\n",
    "                df2.at[row,'Orientation']='+'\n",
    "            elif sense==0 and antisense>0:\n",
    "                df2.at[row,'Orientation']='-'\n",
    "            elif sense>antisense:\n",
    "                df2.at[row,'Orientation']='+'\n",
    "            elif antisense>sense:\n",
    "                df2.at[row,'Orientation']='-'\n",
    "            else:\n",
    "                continue\n",
    "    return(df2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f5ffd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tailCounter(df):\n",
    "    \n",
    "    df2= df.copy()\n",
    "    df2['FILTER_RESULTS']='Good_Row'\n",
    "    df2['Tail_Begins']='No_Tail_Detected'\n",
    "    df2['Tail_Type']='No_Tail_Type'\n",
    "    df2['Tail_Length']=0\n",
    "    df2['Tail_Seed_Hits']=0\n",
    "    \n",
    "    for row in df2.index:\n",
    "        \n",
    "\n",
    "        sequence = str(df2.at[row,'Sequence']).upper()\n",
    "        \n",
    "        tTail = 'TTTTT'\n",
    "        tTailFlag=0\n",
    "        trunningTotal = 0\n",
    "        tTailList=[]\n",
    "        \n",
    "        if tTail in sequence:\n",
    "            taillength=0\n",
    "            findings = [int(x) for x in find_sequence(sequence, tTail)]\n",
    "            if len(findings)>0:\n",
    "                tTailFlag=1\n",
    "                tmin = min(findings)\n",
    "                \n",
    "                iterable = findings\n",
    "                df2.at[row,'Tail_Seed_Hits']=len(findings)\n",
    "                groupings = [list(group) for group in mit.consecutive_groups(iterable)]\n",
    "                flag=0\n",
    "                for group in groupings:\n",
    "                    if flag==0:\n",
    "\n",
    "                        taillength+= len(tTail) + (len(group)-1)\n",
    "                        groupEnd = max(group)+len(tTail)\n",
    "                        flag=1\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        if min(group)-groupEnd<=4:\n",
    "                            taillength+= (len(tTail) + (len(group)-1) + abs(min(group)-groupEnd))\n",
    "                            groupEnd = max(group)+len(tTail)\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                tTailLength = taillength\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        \n",
    "        aTail = 'AAAAA'\n",
    "        aTailFlag=0\n",
    "        arunningTotal = 0\n",
    "        aTailList=[]\n",
    "        if aTail in sequence:\n",
    "            taillength=0\n",
    "            reverseSequence = str(Seq(sequence).reverse_complement())\n",
    "            findings = [int(x) for x in find_sequence(reverseSequence, tTail)]\n",
    "            df2.at[row,'Tail_Seed_Hits']=len(findings)\n",
    "            if len(findings)>0:\n",
    "                aTailFlag=1\n",
    "                amin = min(findings)\n",
    "                iterable = findings\n",
    "                groupings = [list(group) for group in mit.consecutive_groups(iterable)]\n",
    "                flag=0\n",
    "                for group in groupings:\n",
    "                    if flag==0:\n",
    "\n",
    "                        taillength+= len(aTail) + (len(group)-1)\n",
    "                        groupEnd = max(group)+len(aTail)\n",
    "                        flag=1\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        if min(group)-groupEnd<=4:\n",
    "                            taillength+= (len(aTail) + (len(group)-1) + abs(min(group)-groupEnd))\n",
    "                            groupEnd = max(group)+len(aTail)\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                aTailLength = taillength\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        if tTailFlag>0 and aTailFlag==0:\n",
    "            \n",
    "            df2.at[row,'Tail_Begins']=tmin\n",
    "            df2.at[row,'Tail_Type']='Possible_T-Tail'\n",
    "            df2.at[row,'Tail_Length']=tTailLength\n",
    "            \n",
    "        elif tTailFlag==0 and aTailFlag>0:\n",
    "            \n",
    "            df2.at[row,'Tail_Begins']=amin\n",
    "            df2.at[row,'Tail_Type']='Possible_A-Tail'\n",
    "            df2.at[row,'Tail_Length']=aTailLength\n",
    "        \n",
    "        \n",
    "        elif aTailFlag>0 and tTailFlag>0:\n",
    "            \n",
    "            orientation = str(df2.at[row,'Orientation'])\n",
    "            \n",
    "            if tTailLength<aTailLength and amin<tmin:\n",
    "                df2.at[row,'Tail_Begins']=amin\n",
    "                df2.at[row,'Tail_Type']='Possible_A-Tail*_and_Possible_T-Tail'\n",
    "                df2.at[row,'Tail_Length']=aTailLength\n",
    "                \n",
    "            elif tTailLength>aTailLength and tmin<amin:\n",
    "                df2.at[row,'Tail_Begins']=tmin\n",
    "                df2.at[row,'Tail_Type']='Possible_A-Tail_and_Possible_T-Tail*'\n",
    "                df2.at[row,'Tail_Length']=tTailLength\n",
    "                \n",
    "            else:\n",
    "                if orientation !='None':\n",
    "                    \n",
    "                    if tmin>=50 and amin<50:\n",
    "                        df2.at[row,'Tail_Begins']=amin\n",
    "                        df2.at[row,'Tail_Type']='Possible_A-Tail*_and_Possible_T-Tail'\n",
    "                        df2.at[row,'Tail_Length']=aTailLength\n",
    "                    elif tmin<50 and amin>=50:\n",
    "                        df2.at[row,'Tail_Begins']=tmin\n",
    "                        df2.at[row,'Tail_Type']='Possible_A-Tail_and_Possible_T-Tail*'\n",
    "                        df2.at[row,'Tail_Length']=tTailLength\n",
    "                    \n",
    "                        \n",
    "                    elif aTailLength<tTailLength and orientation == '-':\n",
    "                        df2.at[row,'Tail_Begins']=tmin\n",
    "                        df2.at[row,'Tail_Type']='Possible_A-Tail_and_Possible_T-Tail*'\n",
    "                        df2.at[row,'Tail_Length']=tTailLength\n",
    "\n",
    "                    elif aTailLength>tTailLength and orientation == '+':\n",
    "                        df2.at[row,'Tail_Begins']=amin\n",
    "                        df2.at[row,'Tail_Type']='Possible_A-Tail*_and_Possible_T-Tail'\n",
    "                        df2.at[row,'Tail_Length']=aTailLength\n",
    "                        \n",
    "                    elif orientation == '+':\n",
    "                        df2.at[row,'Tail_Begins']=amin\n",
    "                        df2.at[row,'Tail_Type']='Possible_A-Tail*_and_Possible_T-Tail'\n",
    "                        df2.at[row,'Tail_Length']=aTailLength\n",
    "                    \n",
    "                    \n",
    "                    elif orientation == '-':\n",
    "                        df2.at[row,'Tail_Begins']=tmin\n",
    "                        df2.at[row,'Tail_Type']='Possible_A-Tail_and_Possible_T-Tail*'\n",
    "                        df2.at[row,'Tail_Length']=tTailLength\n",
    "                    \n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                \n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return(df2)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe418725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aluLinker(df):\n",
    "    df2 = df.copy()\n",
    "    \n",
    "    for row in df2.index:\n",
    "        \n",
    "        threePrimeFlags=0\n",
    "        \n",
    "        if df2.at[row,'TE_Designation'] == 'SINE/Alu' and str(df2.at[row,'Tail_Type'])!='No_Tail_Type':\n",
    "            \n",
    "            tailDesignation = str(df2.at[row,'Tail_Type'])\n",
    "            tailStartSite = int(df2.at[row,'Tail_Begins'])\n",
    "            elements = ast.literal_eval(str(df2.at[row,'TE_Hits']))\n",
    "            \n",
    "            if len(elements)==1:\n",
    "                for element in elements:\n",
    "\n",
    "                    splitElement = element.split()\n",
    "\n",
    "                    if abs(int(splitElement[12])-tailStartSite)>=120 and abs(int(splitElement[12])-tailStartSite)<=150:\n",
    "                        threePrimeFlags+=1\n",
    "                    else:\n",
    "                        continue\n",
    "            else:\n",
    "                pass\n",
    "                        \n",
    "            if threePrimeFlags>0:\n",
    "                df2.at[row,'FILTER_RESULTS']=['Alu_Linker_Region_Warning']\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "767be64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalQuickCheck(df):\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    for row in df2.index:\n",
    "            \n",
    "            if str(df2.at[row,'TE_Designation']) =='LINE/L1':\n",
    "                if str(df2.at[row,'Element_Annotation']) == 'L1HS' or str(df2.at[row,'Element_Annotation']) == 'L1PA1' or str(df2.at[row,'Element_Annotation']) == 'L1PA2':\n",
    "                    continue\n",
    "                else:\n",
    "                    if str(df2.at[row,'FILTER_RESULTS']) == 'Good_Row':\n",
    "                        df2.at[row,'FILTER_RESULTS']=['OLDER_LINE_SUBFAMILY']\n",
    "                    else:\n",
    "                        newList = ast.literal_eval(str(df2.at[row,'FILTER_RESULTS']))\n",
    "                        newList.append('OLDER_LINE_SUBFAMILY')\n",
    "                        df2.at[row,'FILTER_RESULTS']=newList\n",
    "                    \n",
    "                    \n",
    "            elif str(df2.at[row,'TE_Designation']) =='SINE/Alu':\n",
    "                \n",
    "                if 'AluY' in str(df2.at[row,'Element_Annotation']):\n",
    "                    continue\n",
    "                else:\n",
    "                    if str(df2.at[row,'FILTER_RESULTS']) == 'Good_Row':\n",
    "                        df2.at[row,'FILTER_RESULTS']=['OLDER_ALU_SUBFAMILY']\n",
    "                    else:\n",
    "                        newList = ast.literal_eval(str(df2.at[row,'FILTER_RESULTS']))\n",
    "                        newList.append('OLDER_ALU_SUBFAMILY')\n",
    "                        df2.at[row,'FILTER_RESULTS']=newList\n",
    "                        \n",
    "                \n",
    "                aluList = ast.literal_eval(str(df2.at[row,'TE_Hits']))\n",
    "                if len(aluList)==1:\n",
    "                    continue\n",
    "                else:\n",
    "                    \n",
    "                    aluHitList=[]\n",
    "                    for hit in aluList:\n",
    "                        splitHit = hit.split()\n",
    "                        if 'Alu' in str(splitHit[9]):\n",
    "                            aluHitList.append(splitHit[9])\n",
    "                        else:\n",
    "                            continue\n",
    "                            \n",
    "                    if len(set(aluHitList))>1:\n",
    "                        if str(df2.at[row,'FILTER_RESULTS']) == 'Good_Row':\n",
    "                            df2.at[row,'FILTER_RESULTS']=['MULTI-ALU_Hits']\n",
    "                        else:\n",
    "                            newList = ast.literal_eval(str(df2.at[row,'FILTER_RESULTS']))\n",
    "                            newList.append('MULTI-ALU_Hits')\n",
    "                            df2.at[row,'FILTER_RESULTS']=newList\n",
    "\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b8048f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalQuickCheck2(df):\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    for row in df2.index:\n",
    "            \n",
    "            if str(df2.at[row,'TE_Designation']) =='LINE/L1':\n",
    "                if int(df2.at[row,'Sequence_Length']) >10000:\n",
    "                    if str(df2.at[row,'FILTER_RESULTS']) == 'Good_Row':\n",
    "                        df2.at[row,'FILTER_RESULTS']=['LINE_>10kLen']\n",
    "                    else:\n",
    "                        newList = ast.literal_eval(str(df2.at[row,'FILTER_RESULTS']))\n",
    "                        newList.append('LINE_>10kLen')\n",
    "                        df2.at[row,'FILTER_RESULTS']=newList\n",
    "                else:\n",
    "                    pass\n",
    "                    \n",
    "                if float(df2.at[row,'Element_Divergence']) >15.0:\n",
    "                    if str(df2.at[row,'FILTER_RESULTS']) == 'Good_Row':\n",
    "                        df2.at[row,'FILTER_RESULTS']=['LINE_DIVERGENCE']\n",
    "                    else:\n",
    "                        newList = ast.literal_eval(str(df2.at[row,'FILTER_RESULTS']))\n",
    "                        newList.append('LINE_DIVERGENCE')\n",
    "                        df2.at[row,'FILTER_RESULTS']=newList\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "            elif str(df2.at[row,'TE_Designation']) =='SINE/Alu':\n",
    "                \n",
    "                if int(df2.at[row,'Sequence_Length']) >500:\n",
    "                    if str(df2.at[row,'FILTER_RESULTS']) == 'Good_Row':\n",
    "                        df2.at[row,'FILTER_RESULTS']=['ALU_>500Len']\n",
    "                    else:\n",
    "                        newList = ast.literal_eval(str(df2.at[row,'FILTER_RESULTS']))\n",
    "                        newList.append('ALU_>500Len')\n",
    "                        df2.at[row,'FILTER_RESULTS']=newList\n",
    "                else:\n",
    "                    pass\n",
    "                    \n",
    "                if float(df2.at[row,'Element_Divergence']) >6.0:\n",
    "                    if str(df2.at[row,'FILTER_RESULTS']) == 'Good_Row':\n",
    "                        df2.at[row,'FILTER_RESULTS']=['ALU_DIVERGENCE']\n",
    "                    else:\n",
    "                        newList = ast.literal_eval(str(df2.at[row,'FILTER_RESULTS']))\n",
    "                        newList.append('ALU_DIVERGENCE')\n",
    "                        df2.at[row,'FILTER_RESULTS']=newList\n",
    "                else:\n",
    "                    continue\n",
    "                        \n",
    "                        \n",
    "            elif str(df2.at[row,'TE_Designation']) =='Retroposon/SVA':\n",
    "                if int(df2.at[row,'Sequence_Length']) >10000:\n",
    "                    if str(df2.at[row,'FILTER_RESULTS']) == 'Good_Row':\n",
    "                        df2.at[row,'FILTER_RESULTS']=['SVA_>10kLen']\n",
    "                    else:\n",
    "                        newList = ast.literal_eval(str(df2.at[row,'FILTER_RESULTS']))\n",
    "                        newList.append('SVA_>10kLen')\n",
    "                        df2.at[row,'FILTER_RESULTS']=newList\n",
    "                else:\n",
    "                    pass\n",
    "                    \n",
    "                if float(df2.at[row,'Element_Divergence']) >15.0:\n",
    "                    if str(df2.at[row,'FILTER_RESULTS']) == 'Good_Row':\n",
    "                        df2.at[row,'FILTER_RESULTS']=['SVA_DIVERGENCE']\n",
    "                    else:\n",
    "                        newList = ast.literal_eval(str(df2.at[row,'FILTER_RESULTS']))\n",
    "                        newList.append('SVA_DIVERGENCE')\n",
    "                        df2.at[row,'FILTER_RESULTS']=newList\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e8d76e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tailCounterCheck(df):\n",
    "    df2 = df.copy()\n",
    "    \n",
    "    for row in df2.index:\n",
    "        if df2.at[row,'Tail_Type']!='No_Tail_Type':\n",
    "            flag=0\n",
    "\n",
    "            if int(df2.at[row,'Tail_Begins'])/int(df2.at[row,'Sequence_Length'])>.5 or int(df2.at[row,'Tail_Begins'])>70:\n",
    "                flag+=1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            if flag ==0:\n",
    "                continue\n",
    "            else:\n",
    "                flagg='Bad_Tail_Position'\n",
    "                if df2.at[row,'FILTER_RESULTS']!='Good_Row':\n",
    "                    tempFlagList = ast.literal_eval(str(df2.at[row,'FILTER_RESULTS']))\n",
    "                    tempFlagList.append(flagg)\n",
    "                    df2.at[row,'FILTER_RESULTS'] = tempFlagList\n",
    "                else:\n",
    "                    df2.at[row,'FILTER_RESULTS'] = [flagg]\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc0cf5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDataTEPercentage(df):\n",
    "    \n",
    "    df2 = df.copy() \n",
    "    df2['Element_Annotation']='No_Element_Annotation'\n",
    "    df2['Element_Divergence']=0.0\n",
    "    df2['TE_Proportion']='NONE'\n",
    "    df2['TE_Percentage']=0.0\n",
    "    \n",
    "    #For each locus\n",
    "    for row in tqdm(df2.index):\n",
    "        \n",
    "        if df2.at[row,'TE_Hits'] == 'NONE' or int(df2.at[row,'Sequence_Length'])>50000:\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "\n",
    "            columnName = 'Sequence'\n",
    "\n",
    "            tempDict={int(x):0 for x in range(1,len(df2.at[row,columnName])+1)}    \n",
    "            tempDict2={}\n",
    "            tempDict3={}\n",
    "            tempDivDict={}\n",
    "\n",
    "            teHitList = ast.literal_eval(str(df2.at[row,'TE_Hits']))\n",
    "\n",
    "            for hit in teHitList:\n",
    "\n",
    "                splitHit = hit.split()\n",
    "                focusElement = str(splitHit[9])\n",
    "                tempDict3[focusElement]=str(splitHit[10])\n",
    "\n",
    "                if focusElement in tempDict2.keys():\n",
    "                    tempDivDict[focusElement].append(float(splitHit[1]))\n",
    "                    pass\n",
    "                else:\n",
    "                    tempDivDict[focusElement]=[float(splitHit[1])]\n",
    "                    tempDict2[focusElement]={x:0 for x in range(1,len(df2.at[row,columnName])+1)}\n",
    "                    pass\n",
    "\n",
    "                for coordinate in range(int(splitHit[5]), int(splitHit[6])+1):\n",
    "                    tempDict[coordinate]+=1\n",
    "                    tempDict2[focusElement][coordinate]+=1\n",
    "\n",
    "            tePercentage = len([x for x in tempDict.values() if x >0])/len(tempDict)\n",
    "\n",
    "            df2.at[row,'TE_Percentage']=float(tePercentage)\n",
    "\n",
    "            #print(tempDict3)\n",
    "            #print(tempDivDict)\n",
    "\n",
    "            if len(tempDict2)==1:\n",
    "                mykey = [x for x in tempDict2.keys()][0]\n",
    "                df2.at[row,'TE_Designation']=str(tempDict3[mykey])\n",
    "                df2.at[row,'TE_Proportion']={mykey:tePercentage}\n",
    "                df2.at[row,'Element_Annotation']=mykey\n",
    "                df2.at[row,'Element_Divergence']=np.median(tempDivDict[mykey][0])\n",
    "\n",
    "            else:\n",
    "\n",
    "                tempDict4 = {x:len([y for y in tempDict2[x].values() if y>0])/len(tempDict) for x in tempDict2.keys()}\n",
    "                #print(tempDict4)\n",
    "                maxKey = max(tempDict4, key=tempDict4.get)\n",
    "                df2.at[row,'TE_Designation']=tempDict3[str(maxKey)]\n",
    "                df2.at[row,'TE_Proportion']=tempDict4\n",
    "                df2.at[row,'Element_Annotation']=maxKey\n",
    "                df2.at[row,'Element_Divergence']=np.median(tempDivDict[maxKey])\n",
    "        \n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c397857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeatmaskerPatternFilter(df):\n",
    "    df2 = df.copy()\n",
    "    annotationList=[]\n",
    "    df2['Unique_Element_Count']='One_Element'\n",
    "    for row in df2.index:\n",
    "        if df2.at[row,'TE_Proportion'] == 'NONE':\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "            prodict = ast.literal_eval(str(df2.at[row,'TE_Proportion']))\n",
    "\n",
    "            if str(df2.at[row,'TE_Designation']) == 'SINE/Alu':\n",
    "                aluList = [x for x in prodict.keys() if 'ALU' in str(x).upper()]\n",
    "                if len(aluList)==1:\n",
    "                    continue\n",
    "                else:\n",
    "                    df2.at[row,'Unique_Element_Count']=\"More_Than_One_Element\"\n",
    "            else:\n",
    "                continue \n",
    "    \n",
    "    \n",
    "    for row in df2.index:\n",
    "        if df2.at[row,'TE_Proportion'] == 'NONE':\n",
    "            continue\n",
    "        else:\n",
    "        \n",
    "            if df2.at[row,'Unique_Element_Count'] == 'One_Element':\n",
    "\n",
    "                tempDict = ast.literal_eval(str(df2.at[row,'TE_Proportion']))\n",
    "                dictLength = len([x for x in tempDict.keys()])\n",
    "\n",
    "                if str(df2.at[row,'TE_Designation']) == 'SINE/Alu':\n",
    "                    if len(ast.literal_eval(str(df2.at[row,'TE_Hits'])))>dictLength:\n",
    "                        df2.at[row,'Unique_Element_Count'] = 'One_Element_ODD'\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "\n",
    "\n",
    "                elif str(df2.at[row,'TE_Designation']) == 'LINE/L1':\n",
    "                    if len(ast.literal_eval(str(df2.at[row,'TE_Hits'])))>dictLength:\n",
    "                        df2.at[row,'Unique_Element_Count'] = 'One_Element_ODD'\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                else:\n",
    "                    if len(ast.literal_eval(str(df2.at[row,'TE_Hits'])))>dictLength:\n",
    "                        df2.at[row,'Unique_Element_Count'] = 'One_Element_ODD'\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "37191bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTwinPriming(df):\n",
    "    df2 = df.copy()\n",
    "    df2['Twin_Priming_Flag']='NONE'\n",
    "    \n",
    "    for row in df2.index:\n",
    "        if df2.at[row,'TE_Designation']=='LINE/L1':\n",
    "            allhits = ast.literal_eval(str(df2.at[row,'TE_Hits']))\n",
    "            orientations = []\n",
    "            for hit in allhits:\n",
    "                splitHit=hit.split()\n",
    "                if str(splitHit[10]) == 'LINE/L1':\n",
    "                    orientations.append(splitHit[8])\n",
    "                else:\n",
    "                    continue\n",
    "            if len(set(orientations))>1:\n",
    "                df2.at[row,'Twin_Priming_Flag']='FLAG'\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39142c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleRepeatCheck(df):\n",
    "    df2 = df.copy()\n",
    "    \n",
    "    for row in df2.index:\n",
    "        if df2.at[row,'TE_Designation']=='Simple_repeat':\n",
    "            tempDict = {x:float(y) for x,y in ast.literal_eval(str(df2.at[row,'TE_Proportion'])).items() if ')n' not in x}\n",
    "            if len(tempDict)>0:\n",
    "                maxKey = str(max(tempDict, key=tempDict.get)).upper()\n",
    "                if 'ALU' in maxKey and len(tempDict) == 1:\n",
    "                    #print(row)\n",
    "                    df2.at[row,'TE_Designation']= 'SINE/Alu'\n",
    "                    df2.at[row,'Element_Annotation']= maxKey\n",
    "\n",
    "                elif'L1' in maxKey and len(tempDict) == 1:\n",
    "                    #print(row)\n",
    "                    df2.at[row,'TE_Designation']= 'LINE/L1'\n",
    "                    df2.at[row,'Element_Annotation']= maxKey\n",
    "\n",
    "                elif 'SVA' in maxKey and len(tempDict) == 1:\n",
    "                    #print(row)\n",
    "                    df2.at[row,'TE_Designation']= 'Retroposon/SVA'\n",
    "                    df2.at[row,'Element_Annotation']= maxKey\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "441db179",
   "metadata": {},
   "outputs": [],
   "source": [
    "goodTEs=['SINE/Alu','LINE/L1','Retroposon/SVA','LTR/ERVK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2157d1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1267/1267 [00:00<00:00, 3027.60it/s]\n"
     ]
    }
   ],
   "source": [
    "arthurhg38List=[]\n",
    "fasta_sequences = SeqIO.parse(open('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hg38/arthurhg38_Sequences.fasta'),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    arthurhg38List.append([name, sequence])\n",
    "\n",
    "arthurhg38DF = pd.DataFrame(data=arthurhg38List, columns=['ID','Sequence']).set_index(\"ID\")\n",
    "arthurhg38DF['Sequence_Length']=[len(x) for x in arthurhg38DF['Sequence']]\n",
    "\n",
    "rmdirectory = '/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hg38/arthurhg38_Sequences.fasta.out'\n",
    "callDict={}\n",
    "with open(rmdirectory, 'r') as file:\n",
    "    lines_after_header = file.readlines()[3:]\n",
    "    for line in lines_after_header:\n",
    "        goodline = ' '.join(line.split())\n",
    "        if str(goodline.split(\" \")[4]) in callDict.keys() and float(goodline.split(\" \")[1])<=20.0:\n",
    "            callDict[str(goodline.split(\" \")[4])]['Annotations'].append(goodline)\n",
    "        elif float(goodline.split(\" \")[1])<=20.0:\n",
    "            callDict[str(goodline.split(\" \")[4])]={'Annotations':[]}\n",
    "            callDict[str(goodline.split(\" \")[4])]['Annotations'].append(goodline)\n",
    "        else:\n",
    "            continue\n",
    "file.close()\n",
    "arthurhg38DF['TE_Hits']='NONE'\n",
    "for row in arthurhg38DF.index:\n",
    "    if row in callDict.keys():\n",
    "        arthurhg38DF.at[row,'TE_Hits']=callDict[row]['Annotations']\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "insDF_Filtered= orientationFinder(simpleRepeatCheck(cleanDataTEPercentage(arthurhg38DF)))\n",
    "insDF_Filtered2 = tailCounter(insDF_Filtered)\n",
    "insDF_Filtered3 = aluLinker(insDF_Filtered2)\n",
    "insDF_Filtered4 = tailCounterCheck(insDF_Filtered3)\n",
    "insDF_Filtered5 =finalQuickCheck(insDF_Filtered4)\n",
    "insDF_Filtered6 = finalQuickCheck2(insDF_Filtered5)\n",
    "insDF_Filtered7 = repeatmaskerPatternFilter(insDF_Filtered6)\n",
    "arthurhg38DFFinal = findTwinPriming(insDF_Filtered7)\n",
    "\n",
    "for row in arthurhg38DFFinal.index:\n",
    "    if arthurhg38DFFinal.at[row,'TE_Designation'] == 'LTR/ERVK':\n",
    "        arthurhg38DFFinal.at[row,'FILTER_RESULTS'] = 'Good_Row'\n",
    "    else:\n",
    "        if arthurhg38DFFinal.at[row,'TE_Designation'] == 'SINE/Alu' and arthurhg38DFFinal.at[row,'Unique_Element_Count'] == 'More_Than_One_Element':\n",
    "            arthurhg38DFFinal.at[row,'FILTER_RESULTS'] = 'BAD_Row'\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "finalGoodPALMERhg38 = arthurhg38DFFinal[(arthurhg38DFFinal['TE_Designation'].isin(goodTEs)) & (arthurhg38DFFinal['FILTER_RESULTS']=='Good_Row') & (arthurhg38DFFinal['Tail_Type']!='No_Tail_Type')].copy()\n",
    "findBadPALMERhg38 = arthurhg38DFFinal.loc[[x for x in arthurhg38DFFinal.index if x not in finalGoodPALMERhg38.index]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9fd5aa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816\n",
      "451\n"
     ]
    }
   ],
   "source": [
    "print(len(finalGoodPALMERhg38))\n",
    "print(len(findBadPALMERhg38))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "52f9a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalGoodPALMERhg38.to_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hg38_putativeGoodCalls_07-24-2024.csv')\n",
    "#findBadPALMERhg38.to_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hg38_putativeBadCalls_07-24-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "811df52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in set(finalGoodPALMERhg38['TE_Designation']):\n",
    "    tempDF = finalGoodPALMERhg38[finalGoodPALMERhg38['TE_Designation']==element].copy()\n",
    "    elementName=element.replace(\"/\",'_')\n",
    "    \n",
    "    #with open('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/goodCallSequences/'+str(elementName)+\"_sequences.fasta\", 'a+') as file:\n",
    "        for row in tempDF.index:\n",
    "            elementName2 = str(tempDF.at[row,'Element_Annotation'])\n",
    "            file.write('>'+str(row)+\"_\"+elementName2+'\\n')\n",
    "            if str(tempDF.at[row,'Orientation']) == '-':\n",
    "                file.write(str(tempDF.at[row,'Sequence'])+\"\\n\")\n",
    "            else:\n",
    "                sequence2 = str(Seq(tempDF.at[row,'Sequence']).reverse_complement())\n",
    "                file.write(sequence2+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e770e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1290/1290 [00:00<00:00, 2884.87it/s]\n"
     ]
    }
   ],
   "source": [
    "arthurhs1List=[]\n",
    "fasta_sequences = SeqIO.parse(open('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hs1/arthurhs1_Sequences.fasta'),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    arthurhs1List.append([name, sequence])\n",
    "\n",
    "arthurhs1DF = pd.DataFrame(data=arthurhs1List, columns=['ID','Sequence']).set_index(\"ID\")\n",
    "arthurhs1DF['Sequence_Length']=[len(x) for x in arthurhs1DF['Sequence']]\n",
    "\n",
    "rmdirectory = '/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hs1/arthurhs1_Sequences.fasta.out'\n",
    "callDict={}\n",
    "with open(rmdirectory, 'r') as file:\n",
    "    lines_after_header = file.readlines()[3:]\n",
    "    for line in lines_after_header:\n",
    "        goodline = ' '.join(line.split())\n",
    "        if str(goodline.split(\" \")[4]) in callDict.keys() and float(goodline.split(\" \")[1])<=20.0:\n",
    "            callDict[str(goodline.split(\" \")[4])]['Annotations'].append(goodline)\n",
    "        elif float(goodline.split(\" \")[1])<=20.0:\n",
    "            callDict[str(goodline.split(\" \")[4])]={'Annotations':[]}\n",
    "            callDict[str(goodline.split(\" \")[4])]['Annotations'].append(goodline)\n",
    "        else:\n",
    "            continue\n",
    "file.close()\n",
    "arthurhs1DF['TE_Hits']='NONE'\n",
    "for row in arthurhs1DF.index:\n",
    "    if row in callDict.keys():\n",
    "        arthurhs1DF.at[row,'TE_Hits']=callDict[row]['Annotations']\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "insDF_Filtered= orientationFinder(simpleRepeatCheck(cleanDataTEPercentage(arthurhs1DF)))\n",
    "insDF_Filtered2 = tailCounter(insDF_Filtered)\n",
    "insDF_Filtered3 = aluLinker(insDF_Filtered2)\n",
    "insDF_Filtered4 = tailCounterCheck(insDF_Filtered3)\n",
    "insDF_Filtered5 =finalQuickCheck(insDF_Filtered4)\n",
    "insDF_Filtered6 = finalQuickCheck2(insDF_Filtered5)\n",
    "insDF_Filtered7 = repeatmaskerPatternFilter(insDF_Filtered6)\n",
    "arthurhs1DFFinal = findTwinPriming(insDF_Filtered7)\n",
    "\n",
    "for row in arthurhs1DFFinal.index:\n",
    "    if arthurhs1DFFinal.at[row,'TE_Designation'] == 'LTR/ERVK':\n",
    "        arthurhs1DFFinal.at[row,'FILTER_RESULTS'] = 'Good_Row'\n",
    "    else:\n",
    "        if arthurhs1DFFinal.at[row,'TE_Designation'] == 'SINE/Alu' and arthurhs1DFFinal.at[row,'Unique_Element_Count'] == 'More_Than_One_Element':\n",
    "            arthurhs1DFFinal.at[row,'FILTER_RESULTS'] = 'BAD_Row'\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "finalGoodPALMERhs1 = arthurhs1DFFinal[(arthurhs1DFFinal['TE_Designation'].isin(goodTEs)) & (arthurhs1DFFinal['FILTER_RESULTS']=='Good_Row') & (arthurhs1DFFinal['Tail_Type']!='No_Tail_Type')].copy()\n",
    "findBadPALMERhs1 = arthurhs1DFFinal.loc[[x for x in arthurhs1DFFinal.index if x not in finalGoodPALMERhs1.index]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8315b75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775\n",
      "515\n"
     ]
    }
   ],
   "source": [
    "print(len(finalGoodPALMERhs1))\n",
    "print(len(findBadPALMERhs1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1f7ef43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'SINE/Alu': 601, 'LINE/L1': 144, 'Retroposon/SVA': 23, 'LTR/ERVK': 7})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(finalGoodPALMERhs1['TE_Designation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "861c40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalGoodPALMERhs1.to_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hs1_putativeGoodCalls_07-24-2024.csv')\n",
    "#findBadPALMERhs1.to_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hs1_putativeBadCalls_07-24-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c0a0c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in set(finalGoodPALMERhs1['TE_Designation']):\n",
    "    tempDF = finalGoodPALMERhs1[finalGoodPALMERhs1['TE_Designation']==element].copy()\n",
    "    elementName=element.replace(\"/\",'_')\n",
    "    \n",
    "    #with open('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/goodCallSequences/'+str(elementName)+\"_hs1_sequences.fasta\", 'a+') as file:\n",
    "        for row in tempDF.index:\n",
    "            elementName2 = str(tempDF.at[row,'Element_Annotation'])\n",
    "            file.write('>'+str(row)+\"_\"+elementName2+'\\n')\n",
    "            if str(tempDF.at[row,'Orientation']) == '-':\n",
    "                file.write(str(tempDF.at[row,'Sequence'])+\"\\n\")\n",
    "            else:\n",
    "                sequence2 = str(Seq(tempDF.at[row,'Sequence']).reverse_complement())\n",
    "                file.write(sequence2+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe212de",
   "metadata": {},
   "source": [
    "## Konkel Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "83e1a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedhg38 =pd.read_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/hg38_allCalls_07-24-2024.csv').set_index(\"Unnamed: 0\")\n",
    "konkelhg38 = mergedhg38[(mergedhg38['Caller_Count']==1) & (mergedhg38['Konkel_Lab']==1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "89633e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SV_Length:1587;TE_Designation:Retroposon/SVA;RM_Annotation:SVA_F;Tail_Type:Possible_T-Tail;Orientation:-'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "konkelhg38.loc['chr1-11770152-INS-1586']['Konkel_Lab_INFO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "39c485e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in set(konkelhg38['TE_Designation']):\n",
    "    tempDF = konkelhg38[konkelhg38['TE_Designation']==element].copy()\n",
    "    elementName=element.replace(\"/\",'_')\n",
    "    \n",
    "    \n",
    "    #with open('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/KonkelSequences/goodCallSequences/'+str(elementName)+\"_hg38_sequences.fasta\", 'a+') as file:\n",
    "        for row in tempDF.index:\n",
    "            elementName = str(konkelhg38.at[row,'Konkel_Lab_INFO'].split(\"RM_Annotation:\")[1].split(\";\")[0])\n",
    "            orientation = str(konkelhg38.at[row,'Konkel_Lab_INFO'].split(\"Orientation:\")[1])\n",
    "            file.write('>'+str(row)+'_'+str(elementName)+'\\n')\n",
    "            if orientation == '-':\n",
    "                file.write(str(tempDF.at[row,'ALT'])+\"\\n\")\n",
    "            else:\n",
    "                sequence2 = str(Seq(tempDF.at[row,'ALT']).reverse_complement())\n",
    "                file.write(sequence2+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "55a4a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedhs1 =pd.read_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/hs1_allCalls_07-24-2024.csv').set_index(\"Unnamed: 0\")\n",
    "konkelhs1 = mergedhs1[(mergedhs1['Caller_Count']==1) & (mergedhs1['Konkel_Lab']==1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f3a51636",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in set(konkelhs1['TE_Designation']):\n",
    "    tempDF = konkelhs1[konkelhs1['TE_Designation']==element].copy()\n",
    "    elementName=element.replace(\"/\",'_')\n",
    "    \n",
    "    \n",
    "    #with open('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/KonkelSequences/goodCallSequences/'+str(elementName)+\"_hs1_sequences.fasta\", 'a+') as file:\n",
    "        for row in tempDF.index:\n",
    "            elementName = str(konkelhs1.at[row,'Konkel_Lab_INFO'].split(\"RM_Annotation:\")[1].split(\";\")[0])\n",
    "            orientation = str(konkelhs1.at[row,'Konkel_Lab_INFO'].split(\"Orientation:\")[1])\n",
    "            file.write('>'+str(row)+'_'+str(elementName)+'\\n')\n",
    "            if orientation == '-':\n",
    "                file.write(str(tempDF.at[row,'ALT'])+\"\\n\")\n",
    "            else:\n",
    "                sequence2 = str(Seq(tempDF.at[row,'ALT']).reverse_complement())\n",
    "                file.write(sequence2+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed9419f",
   "metadata": {},
   "source": [
    "## Filter out the bad calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "02aa129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedhs1 =pd.read_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/hs1_allCalls_07-24-2024.csv').set_index(\"Unnamed: 0\")\n",
    "mergedhg38 =pd.read_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/hg38_allCalls_07-24-2024.csv').set_index(\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "59e03e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14208\n",
      "13991\n"
     ]
    }
   ],
   "source": [
    "print(len(mergedhs1))\n",
    "print(len(mergedhg38))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "17d7dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hg38 bad calls\n",
    "from Bio import SeqIO\n",
    "badhg38Calls=[]\n",
    "\n",
    "badPALMERCalls = pd.read_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hg38_putativeBadCalls_07-24-2024.csv').set_index(\"ID\")\n",
    "for row in badPALMERCalls.index:\n",
    "    badhg38Calls.append(row)\n",
    "\n",
    "input_file='/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/PALMER_UniqueSequences_Checked/LINE_L1_hg38_Duplications_sequences.fasta'\n",
    "fasta_sequences = SeqIO.parse(open(input_file),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    badhg38Calls.append('_'.join(name.split(\"_\")[:2]))\n",
    "    \n",
    "input_file='/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/PALMER_UniqueSequences_Checked/Retroposon_SVA_hg38_Duplications_sequences.fasta'\n",
    "fasta_sequences = SeqIO.parse(open(input_file),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    badhg38Calls.append('_'.join(name.split(\"_\")[:2]))\n",
    "    \n",
    "input_file='/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/PALMER_UniqueSequences_Checked/SINE_Alu_hg38_Duplications_sequences.fasta'\n",
    "fasta_sequences = SeqIO.parse(open(input_file),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    badhg38Calls.append('_'.join(name.split(\"_\")[:2]))\n",
    "    \n",
    "\n",
    "input_file='/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/KonkelSequences/Konkel_Unique_Sequences_Checked/LINE_L1_hg38_Duplications_sequences.fasta'\n",
    "fasta_sequences = SeqIO.parse(open(input_file),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    badhg38Calls.append(name.split(\"_\")[0])\n",
    "    \n",
    "    \n",
    "for row in mergedhg38.index:\n",
    "    if int(mergedhg38.at[row,'PALMER'])==1:\n",
    "        if 'HERV' in str(mergedhg38.at[row,'TE_Designation']):\n",
    "            continue\n",
    "        else:\n",
    "            if 'N' in str(mergedhg38.at[row,'PALMER_INFO'].split(\";\")[6]).upper():\n",
    "                #print(mergedhs1.at[row,'PALMER_INFO'].split(\";\")[6])\n",
    "                badhg38Calls.append(row)\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9dcb99ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984\n"
     ]
    }
   ],
   "source": [
    "print(len(badhg38Calls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "875d5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs1 bad calls\n",
    "badhs1Calls=[]\n",
    "\n",
    "badPALMERCalls = pd.read_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/hs1_putativeBadCalls_07-24-2024.csv').set_index(\"ID\")\n",
    "for row in badPALMERCalls.index:\n",
    "    badhs1Calls.append(row)\n",
    "\n",
    "input_file='/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/PALMER_UniqueSequences_Checked/LINE_L1_hs1_Duplications_sequences.fasta'\n",
    "fasta_sequences = SeqIO.parse(open(input_file),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    badhs1Calls.append('_'.join(name.split(\"_\")[:2]))\n",
    "    \n",
    "input_file='/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/ArthurSequences/PALMER_UniqueSequences_Checked/SINE_Alu_hs1_Duplications_sequences.fasta'\n",
    "fasta_sequences = SeqIO.parse(open(input_file),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    badhs1Calls.append('_'.join(name.split(\"_\")[:2]))\n",
    "    \n",
    "    \n",
    "input_file='/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/KonkelSequences/Konkel_Unique_Sequences_Checked/LINE_L1_hs1_Duplications_Bad_sequences.fasta'\n",
    "fasta_sequences = SeqIO.parse(open(input_file),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    badhs1Calls.append(name.split(\"_\")[0])\n",
    "    \n",
    "for row in mergedhs1.index:\n",
    "    if int(mergedhs1.at[row,'PALMER'])==1:\n",
    "        if 'HERV' in str(mergedhs1.at[row,'TE_Designation']):\n",
    "            continue\n",
    "        else:\n",
    "            if 'N' in str(mergedhs1.at[row,'PALMER_INFO'].split(\";\")[6]).upper():\n",
    "                #print(mergedhs1.at[row,'PALMER_INFO'].split(\";\")[6])\n",
    "                badhs1Calls.append(row)\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "218d9f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(badhs1Calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "25aa21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCalls(df, mylist):\n",
    "    df2 = df.copy()\n",
    "    goodRows=[]\n",
    "    for row in df2.index:\n",
    "        if row in mylist:\n",
    "            continue\n",
    "        else:\n",
    "            goodRows.append(row)\n",
    "    df3 = df2.loc[goodRows].copy()\n",
    "    return(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "efee7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredhs1=filterCalls(mergedhs1,badhs1Calls)\n",
    "filteredhg38=filterCalls(mergedhg38,badhg38Calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ce9dfc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13300\n",
      "13083\n"
     ]
    }
   ],
   "source": [
    "print(len(filteredhs1))\n",
    "print(len(filteredhg38))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "60ed2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def findCallerCounts(df):\n",
    "    df2 = df.copy()\n",
    "    callerCounts=[]\n",
    "    both=0\n",
    "    allcounts=0\n",
    "    pavrows=[]\n",
    "    palmerrows=[]\n",
    "    for row in df2.index:\n",
    "        allcounts+=1\n",
    "        if df2.at[row,'Caller_Count']==2:\n",
    "            callerCounts.append('BOTH')\n",
    "            both+=1\n",
    "        else:\n",
    "            if int(df2.at[row,'Konkel_Lab'])==0:\n",
    "                callerCounts.append(\"PALMER\")\n",
    "                palmerrows.append(row)\n",
    "            else:\n",
    "                callerCounts.append(\"PAV\")\n",
    "                pavrows.append(row)\n",
    "    print('Shared Call Percentage: '+str(both/allcounts))\n",
    "    print('PAV: '+str(collections.Counter(df2.loc[pavrows]['TE_Designation'])))\n",
    "    print('PALMER:' +str(collections.Counter(df2.loc[palmerrows]['TE_Designation'])))\n",
    "    print('\\n')\n",
    "    return(collections.Counter(callerCounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "418212ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "67f78038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared Call Percentage: 0.8415681306306306\n",
      "PAV: Counter({'SINE/Alu': 496, 'LINE/L1': 253, 'Retroposon/SVA': 211, 'snRNA': 1})\n",
      "PALMER:Counter({'SINE/Alu': 1023, 'LINE/L1': 235, 'Retroposon/SVA': 25, 'HERVK': 7})\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'BOTH': 11957, 'PALMER': 1290, 'PAV': 961})"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findCallerCounts(mergedhs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e403eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared Call Percentage: 0.8981954887218045\n",
      "PAV: Counter({'SINE/Alu': 496, 'LINE/L1': 248, 'Retroposon/SVA': 211, 'snRNA': 1})\n",
      "PALMER:Counter({'SINE/Alu': 308, 'LINE/L1': 61, 'Retroposon/SVA': 22, 'HERVK': 7})\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'BOTH': 11946, 'PAV': 956, 'PALMER': 398})"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findCallerCounts(filteredhs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "58115d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hg38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "919f0051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared Call Percentage: 0.8526910156529197\n",
      "PAV: Counter({'SINE/Alu': 363, 'LINE/L1': 233, 'Retroposon/SVA': 197, 'snRNA': 1})\n",
      "PALMER:Counter({'SINE/Alu': 962, 'LINE/L1': 279, 'Retroposon/SVA': 19, 'HERVK': 7})\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'BOTH': 11930, 'PALMER': 1267, 'PAV': 794})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findCallerCounts(mergedhg38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9fb4cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared Call Percentage: 0.9105709699610182\n",
      "PAV: Counter({'SINE/Alu': 363, 'LINE/L1': 231, 'Retroposon/SVA': 197, 'snRNA': 1})\n",
      "PALMER:Counter({'SINE/Alu': 283, 'LINE/L1': 73, 'Retroposon/SVA': 15, 'HERVK': 7})\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'BOTH': 11913, 'PAV': 792, 'PALMER': 378})"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findCallerCounts(filteredhg38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filteredhs1))\n",
    "print(len(filteredhg38))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "30dfd1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filteredhg38.to_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/hg38_allCalls_Cleaned-07-29-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e59516a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filteredhs1.to_csv('/home/mark/Desktop/MEI_Group/HGSVC3/Merged_Callsets/Manuscript/hs1_allCalls_Cleaned-07-29-2024.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
