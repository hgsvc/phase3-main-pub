{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c20cfc35-4f81-4115-8fed-f3bb44f25799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "import collections as col\n",
    "\n",
    "top_folder = pl.Path(\"/home/ebertp/work/projects/hgsvc/2024_busco/per_sample\")\n",
    "\n",
    "\n",
    "def read_karyo_file(file_path):\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", header=0, skiprows=1)\n",
    "    karyo_lut = dict(\n",
    "        ((row.sample, row.asm_unit), row.karyotype) for row in df.itertuples()\n",
    "    )\n",
    "    return karyo_lut\n",
    "\n",
    "\n",
    "sex_specific = col.defaultdict(set)\n",
    "for assembler in [\"verkko\"]:  #, \"hifiasm\"]:\n",
    "    karyo_file = top_folder.joinpath(f\"karyo-est.hgsvc3-{assembler}.tsv\")\n",
    "    karyo_lut = read_karyo_file(karyo_file)\n",
    "\n",
    "    n_samples = 0\n",
    "    gene_status = col.Counter()\n",
    "    for table_file in top_folder.joinpath(assembler).glob(\"*tsv.gz\"):\n",
    "        sample = table_file.name.rsplit(\".\", 5)[0]\n",
    "        df = pd.read_csv(table_file, sep=\"\\t\", header=0)\n",
    "        if assembler == \"verkko\":\n",
    "            df.drop(\"asm-unassigned_label\", axis=1, inplace=True)\n",
    "        sex1 = karyo_lut[(sample, df.columns[1].split(\"_\")[0])]\n",
    "        sex2 = karyo_lut[(sample, df.columns[2].split(\"_\")[0])]\n",
    "        if sex1 == sex2 or sex1 == \"any\" or sex2 == \"any\":\n",
    "            # female\n",
    "            continue\n",
    "        n_samples += 1\n",
    "        hap1_missing = df[\"asm-hap1_label\"] == \"Missing\"\n",
    "        hap2_missing = df[\"asm-hap2_label\"] == \"Missing\"\n",
    "        any_missing = hap1_missing | hap2_missing\n",
    "        df = df.loc[any_missing, :].copy()\n",
    "        df.columns = [\"gene\", sex1, sex2]\n",
    "        for row in df.itertuples():\n",
    "            gene_status[(row.gene, sex1, getattr(row, sex1))] += 1\n",
    "            gene_status[(row.gene, sex2, getattr(row, sex2))] += 1\n",
    "\n",
    "    assert n_samples == 30\n",
    "    for (gene, sex, status), count in gene_status.items():\n",
    "        if status != \"Missing\":\n",
    "            continue\n",
    "        if sex == \"male\":\n",
    "            female = gene_status[(gene, \"female\", \"Missing\")]\n",
    "            male_ratio = round(count/n_samples, 1)\n",
    "            female_ratio = round(female/n_samples, 1)\n",
    "            if male_ratio > 0.9 and female_ratio < 0.1:\n",
    "                sex_specific[\"female\"].add(gene)\n",
    "        if sex == \"female\":\n",
    "            male = gene_status[(gene, \"male\", \"Missing\")]\n",
    "            male_ratio = round(male/n_samples, 1)\n",
    "            female_ratio = round(count/n_samples, 1)\n",
    "            if male_ratio < 0.1 and female_ratio > 0.9:\n",
    "                sex_specific[\"male\"].add(gene)\n",
    "\n",
    "out_list = pl.Path(\n",
    "    \"/home/ebertp/work/code/cubi/project-run-hgsvc-hybrid-assemblies/annotations\",\n",
    "    \"autogen\", \"odb10_primates.sex-specific-genes.txt\"\n",
    ")\n",
    "\n",
    "for sex, genes in sex_specific.items():\n",
    "    out_file = out_list.with_suffix(f\".{sex}.txt\")\n",
    "    with open(out_file, \"w\") as dump:\n",
    "        _ = dump.write(\"\\n\".join(sorted(genes)) + \"\\n\")\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
