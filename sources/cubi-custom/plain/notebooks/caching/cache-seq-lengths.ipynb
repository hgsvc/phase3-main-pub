{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169dfcc-8446-4d2c-83b4-5a09990091c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import collections\n",
    "\n",
    "%cd -q \"/home/ebertp/work/code/cubi/project-run-hgsvc-hybrid-assemblies/notebooks\"\n",
    "\n",
    "_PROJECT_CONFIG_NB = str(pathlib.Path(\"00_project_config.ipynb\").resolve(strict=True))\n",
    "_PLOT_CONFIG_NB = str(pathlib.Path(\"05_plot_config.ipynb\").resolve(strict=True))\n",
    "\n",
    "%run $_PROJECT_CONFIG_NB\n",
    "%run $_PLOT_CONFIG_NB\n",
    "\n",
    "_MYNAME=\"cache-seq-lengths\"\n",
    "_MYSTAMP=get_nb_stamp(_MYNAME)\n",
    "\n",
    "ASSEMBLER=\"verkko\"\n",
    "\n",
    "_SEQLENS_CACHE_FILES = {\n",
    "    \"seqlens\": PROJECT_NB_CACHE.joinpath(f\"cache.seqlens.{ASSEMBLER}.pck\"),\n",
    "    \"gaplens\": PROJECT_NB_CACHE.joinpath(f\"cache.gaplens.{ASSEMBLER}.pck\"),\n",
    "    \"adjlens\": PROJECT_NB_CACHE.joinpath(f\"cache.adjlens.{ASSEMBLER}.pck\"),\n",
    "    \"gapseq\": PROJECT_NB_CACHE.joinpath(f\"cache.gapseq.{ASSEMBLER}.pck\"),\n",
    "    \"gapfree\": PROJECT_NB_CACHE.joinpath(f\"cache.gapfree.{ASSEMBLER}.pck\"),\n",
    "}\n",
    "\n",
    "\n",
    "def get_sample_asm_unit(file_name):\n",
    "\n",
    "    if \"-hifiasm-\" in file_name:\n",
    "        sample, _, asm_unit = file_name.split(\".\")[0].split(\"-\")\n",
    "        sample = f\"{sample}.hsm-ps-sseq\"\n",
    "    else:\n",
    "        parts = file_name.split(\".\")\n",
    "        try:\n",
    "            asm_unit = parts[2].split(\"-\")[1]\n",
    "        except IndexError:\n",
    "            # file name w/o asm unit\n",
    "            asm_unit = None\n",
    "        sample = parts[0] + \".\" + parts[1]\n",
    "    return sample, asm_unit\n",
    "\n",
    "\n",
    "def read_ngap_files():\n",
    "\n",
    "    source_folder = PROJECT_DATA_ROOT.joinpath(\n",
    "        f\"2024_ngaps/hgsvc/{ASSEMBLER}\"\n",
    "    ).resolve(strict=True)\n",
    "\n",
    "    print(\"Reading cache input data from: \", source_folder)\n",
    "\n",
    "    gaplens = collections.Counter()\n",
    "    for bed_file in source_folder.glob(\"*.bed\"):\n",
    "        sample, _ = get_sample_asm_unit(bed_file.name)\n",
    "        df = pd.read_csv(\n",
    "            bed_file, sep=\"\\t\", header=None, skiprows=1,\n",
    "            usecols=[0,3,4], names=[\"seq\", \"sample\", \"length\"]\n",
    "        )\n",
    "        assert df[\"sample\"].iloc[0] == sample\n",
    "        for row in df.itertuples():\n",
    "            gaplens[(sample, row.seq)] += row.length\n",
    "            gaplens[sample] += row.length\n",
    "    if not gaplens:\n",
    "        raise RuntimeError\n",
    "    return gaplens\n",
    "\n",
    "\n",
    "def read_fasta_index_files():\n",
    "\n",
    "    source_folder = PROJECT_DATA_ROOT.joinpath(\n",
    "        f\"2024_fasta_index/hgsvc/{ASSEMBLER}\"\n",
    "    ).resolve(strict=True)\n",
    "\n",
    "    print(\"Reading cache input data from: \", source_folder)\n",
    "\n",
    "    seqlens = collections.Counter()\n",
    "    for fai_file in source_folder.glob(\"*.fai\"):\n",
    "        if \"contaminants\" in fai_file.name:\n",
    "            continue\n",
    "        sample, asm_unit = get_sample_asm_unit(fai_file.name)\n",
    "        df = pd.read_csv(fai_file, sep=\"\\t\", header=None, usecols=[0,1], names=[\"seq\", \"length\"])\n",
    "        for row in df.itertuples():\n",
    "            assert (sample, row.seq) not in seqlens\n",
    "            seqlens[(sample, None, row.seq)] = row.length\n",
    "            seqlens[(sample, asm_unit, row.seq)] = row.length\n",
    "            seqlens[(sample, asm_unit, None)] += row.length\n",
    "            seqlens[sample] += row.length\n",
    "    return seqlens\n",
    "\n",
    "\n",
    "def compute_adjusted_sequence_length():\n",
    "\n",
    "    seqlens = load_seqlen_cache(\"seqlens\")\n",
    "    gaplens = load_seqlen_cache(\"gaplens\")\n",
    "    assert isinstance(gaplens, collections.Counter)\n",
    "\n",
    "    check_keys = [k for k in seqlens.keys() if len(k) > 1 and k[1] is None]\n",
    "    seq_w_gap = collections.defaultdict(set)\n",
    "    seq_wo_gap = collections.defaultdict(set)\n",
    "    adj_seqlen = collections.Counter()\n",
    "    for (smp, _, seq) in check_keys:\n",
    "        gaplen = gaplens[(smp, seq)]\n",
    "        if gaplen > 0:\n",
    "            seq_w_gap[smp].add(seq)\n",
    "        else:\n",
    "            seq_wo_gap[smp].add(seq)\n",
    "        seqlen = seqlens[(smp, None, seq)]\n",
    "        adj_len = seqlen - gaplen\n",
    "        assert adj_len > 0\n",
    "        adj_seqlen[(smp, seq)] = adj_len\n",
    "        adj_seqlen[smp] += adj_len\n",
    "    return adj_seqlen, seq_w_gap, seq_wo_gap\n",
    "\n",
    "\n",
    "def _build_any_seqlen_cache(cache_file, data):\n",
    "    with open(cache_file, \"wb\") as cache:\n",
    "        cache_obj = {\n",
    "            \"data\": data,\n",
    "            \"source\": _MYSTAMP\n",
    "        }\n",
    "        pkl.dump(cache_obj, cache)\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_seqlen_cache(which, force_rebuild=False):\n",
    "\n",
    "    cache_file = _SEQLENS_CACHE_FILES[which]\n",
    "    if force_rebuild or not cache_file.is_file():\n",
    "        if which == \"seqlens\":\n",
    "            seqlens = read_fasta_index_files()\n",
    "            _ = _build_any_seqlen_cache(cache_file, seqlens)\n",
    "        elif which == \"gaplens\":\n",
    "            gaplens = read_ngap_files()\n",
    "            _ = _build_any_seqlen_cache(cache_file, gaplens)\n",
    "        elif which in [\"adjlens\", \"gapfree\", \"gapseq\"]:\n",
    "            _ = build_seqlen_cache(\"seqlens\", force_rebuild)\n",
    "            _ = build_seqlen_cache(\"gaplens\", force_rebuild)\n",
    "            adjlens, seq_w_gap, gapfree_seq = compute_adjusted_sequence_length()\n",
    "            cache_file = _SEQLENS_CACHE_FILES[\"adjlens\"]\n",
    "            _ = _build_any_seqlen_cache(cache_file, adjlens)\n",
    "            cache_file = _SEQLENS_CACHE_FILES[\"gapfree\"]\n",
    "            _ = _build_any_seqlen_cache(cache_file, gapfree_seq)\n",
    "            cache_file = _SEQLENS_CACHE_FILES[\"gapseq\"]\n",
    "            _ = _build_any_seqlen_cache(cache_file, seq_w_gap)\n",
    "        else:\n",
    "            raise ValueError(which)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "\n",
    "def load_seqlen_cache(which, force_rebuild=False, report_source=False):\n",
    "\n",
    "    cache_file = _SEQLENS_CACHE_FILES[which]\n",
    "    _ = build_seqlen_cache(which, force_rebuild)\n",
    "    with open(cache_file, \"rb\") as cache:\n",
    "        cache_obj = pkl.load(cache)\n",
    "        if report_source:\n",
    "            src = cache_obj[\"source\"]\n",
    "            print(f\"Loading cache file {CACHE_FILE_SEQLEN}\\nSource: {src}\\n\")\n",
    "        data = cache_obj[\"data\"]\n",
    "    return data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
