{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7306babc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(921, 30)\n"
     ]
    }
   ],
   "source": [
    "%run \"../../00_project_config.ipynb\"\n",
    "%run \"../00_path_config.ipynb\"\n",
    "\n",
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "import re\n",
    "import itertools as itt\n",
    "import hashlib as hl\n",
    "import collections as col\n",
    "import pickle as pck\n",
    "\n",
    "acc_table_file = PROJECT_BASE.joinpath(\n",
    "    \"annotations\", \"data_freezes\",\n",
    "    \"out-120.hgsvc3_data_sources.prep.tsv\"\n",
    ")\n",
    "acc_table = pd.read_csv(acc_table_file, sep=\"\\t\", header=0, comment=\"#\")\n",
    "\n",
    "sseq_remote_cache_file = pl.Path(\".\").resolve().parent.joinpath(\n",
    "    \".cache\", \"sseq_igsr_folders.pck\"\n",
    ")\n",
    "assert sseq_remote_cache_file.is_file()\n",
    "\n",
    "with open(sseq_remote_cache_file, \"rb\") as dump:\n",
    "    sseq_raw_cache = pck.load(dump)\n",
    "\n",
    "def process_sseq_cache(sseq_cache):\n",
    "    \n",
    "    sseq_folders = col.defaultdict(list)\n",
    "    for wd, sub_entries in sseq_cache.items(): \n",
    "        if \"hgsvc2\" in wd.lower():\n",
    "            sub_path = wd.split(\"HGSVC2\")[-1].strip().strip(\"/\")\n",
    "            remote_path = \"IGSR:HGSVC2:/\" + sub_path\n",
    "        elif \"hgsvc3\" in wd.lower():\n",
    "            sub_path = wd.split(\"HGSVC3\")[-1].strip().strip(\"/\")\n",
    "            remote_path = \"IGSR:HGSVC3:/\" + sub_path\n",
    "        else:\n",
    "            raise\n",
    "        if sub_path.endswith(\"fastq\"):\n",
    "            search_path = sub_path.split(\"/\")[-2]\n",
    "        else:\n",
    "            search_path = sub_path.split(\"/\")[-1]            \n",
    "        for entry in sub_entries:\n",
    "            if \"readme\" in entry.lower() or \"manifest\" in entry.lower():\n",
    "                continue\n",
    "            # infer SIN\n",
    "            mobj = re.search(\"[0-9]{5}\", entry)\n",
    "            if mobj is None:\n",
    "                raise ValueError(wd, entry)\n",
    "            s, e = mobj.span()\n",
    "            sin = f\"SIN:{entry[s:e]}\"\n",
    "            assert len(sin) == 9, entry\n",
    "            sample_remote = remote_path + f\"/{entry}\"\n",
    "            sseq_folders[sin].append(\n",
    "                (search_path, sample_remote)\n",
    "            )\n",
    "    return sseq_folders\n",
    "\n",
    "\n",
    "sseq_remotes = process_sseq_cache(sseq_raw_cache)\n",
    "\n",
    "\n",
    "def get_remote_prefix_header():\n",
    "    \n",
    "    header = \"\"\n",
    "    with open(acc_table_file, \"r\") as table:\n",
    "        _ = table.readline()\n",
    "        for line in table:\n",
    "            if not line.startswith(\"#\"):\n",
    "                break\n",
    "            header += line.strip()\n",
    "            header += \"\\n\"\n",
    "    assert header\n",
    "    return header\n",
    "\n",
    "file_table_file = PROJECT_BASE.joinpath(\n",
    "    \"annotations\", \"data_freezes\",\n",
    "    \"out-130.hgsvc3_data_sources.files.tsv\"\n",
    ")\n",
    "file_table = pd.read_csv(file_table_file, sep=\"\\t\", header=0, comment=\"#\")\n",
    "\n",
    "output_table = PROJECT_BASE.joinpath(\n",
    "    \"annotations\", \"data_freezes\",\n",
    "    \"out-140.hgsvc3_data_sources.unpolished.tsv\"\n",
    ")\n",
    "\n",
    "sample_info_lut = dict()\n",
    "for row in acc_table.itertuples():\n",
    "    infos = {\n",
    "        \"family\": row.family,\n",
    "        \"member\": row.member,\n",
    "        \"population\": row.population,\n",
    "        \"supergroup\": row.supergroup,\n",
    "        \"hgsvc_sample_number\": row.hgsvc_sample_number,\n",
    "        \"phase\": row.phase,\n",
    "        \"sample\": row.sample,\n",
    "        \"sex\": row.sex,\n",
    "        \"is_child\": row.is_child,\n",
    "        \"verkko_assembly_batch\": row.verkko_assembly_batch\n",
    "    }\n",
    "    sample_info_lut[row.SIN] = infos   \n",
    "sample_info = pd.DataFrame.from_records(sample_info_lut).transpose()\n",
    "sample_info = sample_info.reset_index(drop=False, inplace=False)\n",
    "sample_info.rename({\"index\": \"SIN\"}, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "join_keys = []\n",
    "for row in acc_table.itertuples():\n",
    "    select_sin = file_table[\"SIN\"] == row.SIN\n",
    "    select_datatype = file_table[\"datatype\"] == row.datatype\n",
    "    remote_exact = file_table[\"remote_path\"] == row.remote_path\n",
    "    remote_maybe = file_table[\"remote_path\"] == f\"{row.remote_path}/{row.sample}\"\n",
    "    remote_fuzzy = file_table[\"remote_path\"] == f\"{row.remote_path}/{'GM'+row.sample[2:]}\"\n",
    "    not_all = file_table[\"filename\"] != \"all\"\n",
    "    \n",
    "    selector = not_all & select_sin & select_datatype & (remote_exact | remote_maybe | remote_fuzzy)\n",
    "    \n",
    "    if selector.any():\n",
    "        file_rows = file_table.index[selector]\n",
    "        all_keys = sorted([row.Index] + file_rows)\n",
    "        join_key = \"\".join(map(str, all_keys))\n",
    "        join_key = hl.md5(join_key.encode(\"utf-8\")).hexdigest()\n",
    "        join_keys.append(\n",
    "            (join_key, row.Index, file_rows)\n",
    "        )       \n",
    "            \n",
    "acc_table[\"join_key\"] = \"unknown\"\n",
    "file_table[\"join_key\"] = \"unknown\"\n",
    "\n",
    "for jk, acc_idx, file_idx in join_keys:\n",
    "    acc_table.loc[acc_idx, \"join_key\"] = jk\n",
    "    file_table.loc[file_idx, \"join_key\"] = jk\n",
    "    \n",
    "subset_acc = acc_table.loc[acc_table[\"join_key\"] != \"unknown\", :].copy()\n",
    "subset_acc.drop(\"remote_path\", axis=1, inplace=True)\n",
    "subset_file = file_table.loc[file_table[\"join_key\"] != \"unknown\", :].copy()\n",
    "\n",
    "direct_match = subset_acc.merge(subset_file, on=[\"join_key\", \"SIN\", \"datatype\"], how=\"outer\")\n",
    "\n",
    "subset_acc2 = acc_table.loc[acc_table[\"join_key\"] == \"unknown\", :].copy()\n",
    "subset_file2 = file_table.loc[file_table[\"join_key\"] == \"unknown\", :].copy()\n",
    "\n",
    "# same procedure for matches w/o remote\n",
    "join_keys = []\n",
    "for row in subset_acc2.itertuples():\n",
    "    select_sin = subset_file2[\"SIN\"] == row.SIN\n",
    "    select_datatype = subset_file2[\"datatype\"] == row.datatype\n",
    "    not_all = subset_file2[\"filename\"] != \"all\"\n",
    "    \n",
    "    selector = select_sin & select_datatype & not_all\n",
    "    \n",
    "    if selector.any():\n",
    "        # NB: this requires that subset_file2\n",
    "        # was not re-indexed!\n",
    "        file_rows = subset_file2.index[selector]\n",
    "        all_keys = sorted([row.Index] + file_rows)\n",
    "        join_key = \"\".join(map(str, all_keys))\n",
    "        join_key = hl.md5(join_key.encode(\"utf-8\")).hexdigest()\n",
    "        join_keys.append(\n",
    "            (join_key, row.Index, file_rows)\n",
    "        )       \n",
    "\n",
    "for jk, acc_idx, file_idx in join_keys:\n",
    "    assert acc_table.loc[acc_idx, \"join_key\"] == \"unknown\"\n",
    "    acc_table.loc[acc_idx, \"join_key\"] = jk\n",
    "    file_table.loc[file_idx, \"join_key\"] = jk\n",
    "\n",
    "# the remote for strand-seq is approximately correct,\n",
    "# hence save that here before dropping that info\n",
    "sseq_acc = acc_table.loc[acc_table[\"datatype\"] == \"strandseq\", :].copy()\n",
    "\n",
    "seen_idx = set()\n",
    "for sseq_sin, remotes in sseq_remotes.items():\n",
    "    if sseq_sin not in sseq_acc[\"SIN\"].values:\n",
    "        continue\n",
    "    subset = sseq_acc.loc[sseq_acc[\"SIN\"] == sseq_sin, :]\n",
    "    \n",
    "    matched = 0\n",
    "    update_remotes = []\n",
    "    for row in subset.itertuples():\n",
    "        for remote in remotes:\n",
    "            if remote[0] in row.remote_path or row.remote_path == \"unknown\":\n",
    "                matched += 1\n",
    "                assert row.Index not in seen_idx\n",
    "                update_remotes.append((row.Index, remote[1]))\n",
    "                seen_idx.add(row.Index)\n",
    "                break\n",
    "    assert matched == subset.shape[0]\n",
    "    \n",
    "    for idx, new_remote in update_remotes:\n",
    "        sseq_acc.loc[idx, \"remote_path\"] = new_remote\n",
    "\n",
    "acc_table.drop(\"remote_path\", axis=1, inplace=True)\n",
    "\n",
    "select_acc = acc_table[\"join_key\"] != \"unknown\"\n",
    "select_files = file_table[\"join_key\"] != \"unknown\"\n",
    "\n",
    "merged = acc_table.loc[select_acc, :].copy(\n",
    "    ).merge(file_table.loc[select_files, :].copy(), on=[\"join_key\", \"SIN\", \"datatype\"])\n",
    "\n",
    "\n",
    "remain_acc = ~select_acc\n",
    "assert (acc_table.loc[remain_acc, \"datatype\"] == \"strandseq\").all()\n",
    "# to be appended - all strandseq pointers\n",
    "# this is thus equivalent to the 'sseq_acc' object\n",
    "# set aside above\n",
    "\n",
    "# the following requires some manual fixes\n",
    "remain_files = ~select_files\n",
    "remain_files = file_table.loc[remain_files, :].copy()\n",
    "remain_files[\"accession\"] = \"unknown\"\n",
    "\n",
    "\n",
    "remain_files = remain_files.merge(sample_info, left_on=[\"SIN\"], right_on=[\"SIN\"])\n",
    "\n",
    "# NB: sseq_acc info added verbatim to keep remote_path intact\n",
    "complete_merge = pd.concat(\n",
    "    [merged, sseq_acc, remain_files],\n",
    "    axis=0, ignore_index=False\n",
    ")\n",
    "\n",
    "for col in complete_merge.columns:\n",
    "    if \"cov\" in col:\n",
    "        complete_merge[col].fillna(0., inplace=True)\n",
    "    if \"num\" in col or \"length\" in col:\n",
    "        complete_merge[col].fillna(0, inplace=True)\n",
    "        complete_merge[col] = complete_merge[col].astype(int)\n",
    "\n",
    "# set filename to unknown for strandseq\n",
    "select_dtype = complete_merge[\"datatype\"] == \"strandseq\"\n",
    "complete_merge.loc[select_dtype, \"filename\"] = \"unknown\"\n",
    "select_no_remote = complete_merge[\"remote_path\"] == \"unknown\"\n",
    "complete_merge.loc[select_dtype & select_no_remote, \"igsr_folder_exists\"] = \"unknown\"\n",
    "complete_merge.loc[select_dtype & select_no_remote, \"igsr_file_exists\"] = \"unknown\"\n",
    "select_igsr_remote = complete_merge[\"remote_path\"].str.contains(\"HGSVC\")\n",
    "complete_merge.loc[select_dtype & select_igsr_remote, \"igsr_folder_exists\"] = \"yes\"\n",
    "complete_merge.loc[select_dtype & select_igsr_remote, \"igsr_file_exists\"] = \"unknown\"\n",
    "\n",
    "\n",
    "source_prefix_header = get_remote_prefix_header()\n",
    "with open(output_table, \"w\") as dump:\n",
    "    _ = dump.write(f\"# {TODAY}\\n\")\n",
    "    _ = dump.write(source_prefix_header)\n",
    "    complete_merge.to_csv(dump, sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "print(complete_merge.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
