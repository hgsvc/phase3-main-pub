{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88d72dc7-7f10-4954-8764-50c4a7e5cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import collections as col\n",
    "import difflib as diffl\n",
    "\n",
    "%cd -q \"/home/ebertp/work/code/cubi/project-run-hgsvc-hybrid-assemblies/notebooks\"\n",
    "\n",
    "_PROJECT_CONFIG_NB = str(pathlib.Path(\"00_project_config.ipynb\").resolve(strict=True))\n",
    "\n",
    "%run $_PROJECT_CONFIG_NB\n",
    "\n",
    "def read_accession_table(file_path, load_columns, renamed=(\"file_accession\", \"project_accession\", \"file_name\")):\n",
    "\n",
    "    if file_path.suffix == \".tsv\":\n",
    "        sep = \"\\t\"\n",
    "    elif file_path.suffix == \".csv\":\n",
    "        sep = \",\"\n",
    "    else:\n",
    "        raise ValueError(file_path.suffix)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=sep, usecols=load_columns)\n",
    "        df.rename(\n",
    "            dict((lc, rc) for lc, rc in zip(load_columns, renamed)),\n",
    "            axis=1, inplace=True\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(file_path.name)\n",
    "        raise\n",
    "\n",
    "    file_lut = dict()\n",
    "    for row in df.itertuples():\n",
    "        just_file = row.file_name\n",
    "        if \"/\" in just_file:\n",
    "            just_file = just_file.split(\"/\")[-1] \n",
    "        if just_file.endswith(\".fastq.gz\"):\n",
    "            plain = just_file.rsplit(\".\", 2)[0]\n",
    "        elif just_file.endswith(\".bam\"):\n",
    "            plain = just_file.rsplit(\".\", 1)[0]\n",
    "        elif just_file.endswith(\".hifi_reads\"):\n",
    "            plain = just_file\n",
    "        elif \"illumina\" in just_file.lower():\n",
    "            continue\n",
    "        elif \"6U00\" in just_file:\n",
    "            continue\n",
    "        elif \"hifi\" in just_file.lower():\n",
    "            plain = just_file\n",
    "        elif \"-clr-\" in just_file.lower():\n",
    "            continue\n",
    "        elif just_file.startswith(\"PL\") and just_file.endswith(\"run\"):\n",
    "            # 2024-08-14 manual fix for EDEVI data\n",
    "            plain = just_file\n",
    "        else:\n",
    "            raise ValueError(file_path.name, row.file_name)\n",
    "            continue\n",
    "            \n",
    "        file_lut[plain] = (row.file_accession, row.project_accession)\n",
    "\n",
    "    return file_lut\n",
    "        \n",
    "LOAD_FOLDER = PROJECT_BASE.joinpath(\"annotations\", \"external\", \"accessions\")\n",
    "\n",
    "accession_tables = [\n",
    "    (\n",
    "        \"20240522_HGSVC3-ENA_fastq_upload-summary_UW.YoungjunKwon.tsv\",\n",
    "        (\"runId\", \"project_accession\", \"file_name\"),\n",
    "        None\n",
    "    ),\n",
    "    (\n",
    "        \"20240521_PacBioHiFi_runs_JAX.PilleHallast.tsv\",\n",
    "        (\"id\", \"project_accession\", \"file_name\"),\n",
    "        None\n",
    "    ),\n",
    "    (\n",
    "        \"20240521_ONT-UL_runs_JAX.PilleHallast.tsv\",\n",
    "        (\"id\", \"project_accession\", \"file_name\"),\n",
    "        None\n",
    "    ),\n",
    "    (\n",
    "        \"PRJEB58376_ENA_filereport.tsv\",\n",
    "        (\"run_accession\", \"study_accession\", \"submitted_ftp\"),\n",
    "        None\n",
    "    ),\n",
    "    (\n",
    "        \"PRJNA339722_ENA_filereport.tsv\",\n",
    "        (\"run_accession\", \"study_accession\", \"run_alias\"),\n",
    "        None\n",
    "    ),\n",
    "    (\n",
    "        \"PRJNA731524_ENA_filereport.tsv\",\n",
    "        (\"run_accession\", \"study_accession\", \"run_alias\"),\n",
    "        None\n",
    "    ),\n",
    "    (\n",
    "        \"PRJNA988114_ENA_filereport.tsv\",\n",
    "        (\"run_accession\", \"study_accession\", \"run_alias\"),\n",
    "        \"ONT for 2 samples / chrY paper / UW\"\n",
    "    ),\n",
    "    (\n",
    "        \"PRJEB36100_ENA_filereport.tsv\",\n",
    "        (\"run_accession\", \"study_accession\", \"run_alias\"),\n",
    "        \"See KM Email 2024-07-10/11 - UW data / HGSVC2\"\n",
    "    ),\n",
    "    (\n",
    "        \"20240813_HGSVC3-ENA_FASTQ_Accessions_2024_08_13.YK.tsv\",\n",
    "        (\"runId\", \"project_accession\", \"file_name\"),\n",
    "        None\n",
    "    ),\n",
    "    (\n",
    "        \"20240716_ena-upload_jax-hifi-singleton.csv\",\n",
    "        (\"id\", \"studyId\", \"filename\"),\n",
    "        \"Single file upload from JAX / NA19238 hifi\"\n",
    "    ),\n",
    "    (\n",
    "        \"PRJNA698480_ENA_filereport.tsv\",\n",
    "        (\"run_accession\", \"study_accession\", \"run_alias\"),\n",
    "        \"PacBio data HGSVC2\"\n",
    "    ),\n",
    "    (\n",
    "        \"PRJEB41778_filereport_ENA.tsv\",\n",
    "        (\"run_accession\", \"study_accession\", \"submitted_ftp\"),\n",
    "        \"PacBio data HGSVC2\"\n",
    "    )\n",
    "]\n",
    "\n",
    "all_files = col.defaultdict(set)\n",
    "for table_file, load_columns, _ in accession_tables:\n",
    "    acc_files = read_accession_table(LOAD_FOLDER.joinpath(table_file), load_columns)\n",
    "    for k,v in acc_files.items():\n",
    "        all_files[k].add(v)\n",
    "\n",
    "data_freeze = pd.read_csv(\n",
    "    PROJECT_BASE.joinpath(\"annotations\", \"data_freezes\", \"hgsvc3_assembly_data_sources.draft.tsv\"),\n",
    "    comment=\"#\", sep=\"\\t\"\n",
    ")\n",
    "\n",
    "def check_approx_match(query, targets):\n",
    "\n",
    "    debug = False\n",
    "    debug_files = []\n",
    "    debug = any([query == f for f in debug_files])\n",
    "\n",
    "    match_quality = \"fuzzy-match\"\n",
    "\n",
    "    # 2024-08-14 manual fix for EDEVI data\n",
    "    if \"EDEVI\" in query:\n",
    "        parts = query.split(\"_\")\n",
    "        lib_id = [p for p in parts if p.startswith(\"PL\")]\n",
    "        if len(lib_id) == 1:\n",
    "            query = lib_id[0]\n",
    "            match_quality = \"manual-fix\"\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # 2024-08-14 manual fix for problematic submission\n",
    "    # HG02818 lib 1 has three submitted BAMs carrying different movie IDs\n",
    "    # but that are part of the same run. The used file carries the movie ID\n",
    "    # from one BAM, but the run alias is set to the name of another BAM,\n",
    "    # hence we switch out the query here\n",
    "    # This is in metadata for project PRJNA731524\n",
    "    # See email thread with KM and Chad Tomlinson July 2023 (!)\n",
    "    # The HG02818 data may have been submitted multiple times as well,\n",
    "    # potentially also under PRJNA339722 but that project does not contain\n",
    "    # sufficient metadata to match the files\n",
    "    if query == \"HG02818_m64043_200209_061852.SRR14611219.lib1\":\n",
    "        query = \"m64043_200206_173947.ccs\"\n",
    "        match_quality = \"manual-fix\"\n",
    "    if query == \"m64043_200207_235213.ccs\":\n",
    "        # same as before\n",
    "        query = \"m64043_200206_173947.ccs\"\n",
    "        match_quality = \"manual-fix\"\n",
    "\n",
    "    # 2024-08-14 manual fix for submission that is inconsistent in its use of\n",
    "    # run vs movie identifiers\n",
    "    # email exchange with KM 2024-07-10/11\n",
    "    if query == \"m54329U_200719_061020.ccs\":\n",
    "        query = \"HG00514-HiFi-r54329U_20200717_234302-B01\"\n",
    "        match_quality = \"manual-fix\"\n",
    "    if query == \"m54329U_200717_235548.ccs\":\n",
    "        query = \"HG00514-HiFi-r54329U_20200717_234302-A01\"\n",
    "        match_quality = \"manual-fix\"\n",
    "    if query == \"m54329U_200715_194535.ccs\":\n",
    "        query = \"HG00514-HiFi-r54329U_20200715_193257-A01\"\n",
    "        match_quality = \"manual-fix\"\n",
    "    \n",
    "    sm = diffl.SequenceMatcher()\n",
    "    sm.set_seq2(query)\n",
    "    max_sim = 0\n",
    "    selected_t = None\n",
    "    for t in targets:\n",
    "        sm.set_seq1(t)\n",
    "        match = sm.find_longest_match()\n",
    "        frac_q = match.size / len(query)\n",
    "        frac_t = match.size / len(t)\n",
    "        frac = max(frac_q, frac_t)\n",
    "        if frac > max_sim:\n",
    "            max_sim = frac\n",
    "            selected_t = t\n",
    "\n",
    "    if debug:\n",
    "        print(query)\n",
    "        print(max_sim)\n",
    "        print(selected_t)\n",
    "        raise\n",
    "    \n",
    "    if max_sim > 0.999:\n",
    "        return selected_t, match_quality\n",
    "    elif max_sim > 0.8:\n",
    "        #print(query, \" <---> \", selected_t)\n",
    "        return selected_t, match_quality\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "missing = []\n",
    "found = []\n",
    "known_files = list(all_files.keys())\n",
    "\n",
    "for row in data_freeze.itertuples():\n",
    "    if row.filename == \"all\":\n",
    "        continue\n",
    "    if row.datatype == \"strandseq\":\n",
    "        continue    \n",
    "    if row.filename.endswith(\".fastq.gz\"):\n",
    "        plain = row.filename.rsplit(\".\", 2)[0]\n",
    "    else:\n",
    "        raise ValueError(row.filename)\n",
    "\n",
    "    if row.sample == \"NA24385\":\n",
    "        if row.datatype == \"ont\":\n",
    "            project_accession = \"AWS:S3:human-pangenomics:NHGRI_UCSC_panel/HG002/nanopore/ultra-long\"\n",
    "        else:\n",
    "            project_accession = row.accession\n",
    "        found.append(\n",
    "            (\n",
    "                row.sample, row.datatype, plain,\n",
    "                \"exact-match\", \"exact-match\",\n",
    "                row.accession, \"external\", project_accession,\n",
    "                0, \"yes\", row.Index\n",
    "            )\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # 2024-08-14 manual fixes after discussions with all involved parties\n",
    "    if row.filename == \"20230626_230620_23-lee-007_PCA100115_3F-run15_guppy-5.0.11-sup-prom_fastq_pass.fastq.gz\":\n",
    "        found.append(\n",
    "            (\n",
    "                row.sample, row.datatype, plain,\n",
    "                \"exact-match\", \"exact-match\", \"no-accession\", \"no-accession\",\n",
    "                \"no-accession\", 0, \"no-contaminant-drop\", row.Index\n",
    "            )\n",
    "        )\n",
    "        continue\n",
    "    \n",
    "    if plain not in all_files:\n",
    "        approx_match, matchq = check_approx_match(plain, known_files)\n",
    "        if approx_match is not None:\n",
    "            file_accessions = all_files[approx_match]\n",
    "            if len(file_accessions) > 1:\n",
    "                dup_acc = 1\n",
    "            else:\n",
    "                dup_acc = 0\n",
    "            for accessions in file_accessions:\n",
    "                file_acc, proj_acc= accessions\n",
    "                found.append(\n",
    "                    (\n",
    "                        row.sample, row.datatype, plain,\n",
    "                        approx_match, matchq, row.accession,\n",
    "                        file_acc, proj_acc, dup_acc, \"yes\", row.Index\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            missing.append((row.sample, row.datatype, plain, row.remote_path, row.accession))\n",
    "    else:\n",
    "        file_accessions = all_files[plain]\n",
    "        if len(file_accessions) > 1:\n",
    "            dup_acc = 1\n",
    "        else:\n",
    "            dup_acc = 0\n",
    "    \n",
    "        for accessions in file_accessions:\n",
    "            file_acc, proj_acc = accessions\n",
    "            found.append(\n",
    "                (\n",
    "                    row.sample, row.datatype, plain,\n",
    "                    \"exact-match\", \"exact-match\",\n",
    "                    row.accession, file_acc, proj_acc,\n",
    "                    dup_acc, \"yes\", row.Index\n",
    "                )\n",
    "            )\n",
    "\n",
    "if missing:\n",
    "    print(\"Missing files / dumping to file\")\n",
    "    with open(\"hgsvc3_missing_accessions.hifi-ont.ALL.tsv\", \"w\") as dump:\n",
    "        dump.write(\"\\t\".join([\"sample\", \"datatype\", \"file_name\", \"remote_path\", \"accession\"]) + \"\\n\")\n",
    "        for m in missing:\n",
    "            dump.write(\"\\t\".join(m) + \"\\n\")\n",
    "\n",
    "\n",
    "found = pd.DataFrame.from_records(\n",
    "    found,\n",
    "    columns=[\n",
    "        \"sample\", \"datatype\", \"filename\", \"matched_name\", \"match_quality\",\n",
    "        \"annotated_project\", \"file_accession\", \"project_accession\", \"has_duplicated_accession\",\n",
    "        \"reuse_data\", \"df_idx\"\n",
    "    ]\n",
    ")\n",
    "dups = found.loc[found[\"has_duplicated_accession\"] > 0, :]\n",
    "\n",
    "drop_dup_indices = []\n",
    "for acc, file_infos in dups.groupby(\"filename\"):\n",
    "    # if annotated == matched, select that\n",
    "    select_by_project = file_infos[\"annotated_project\"] == file_infos[\"project_accession\"]\n",
    "    if select_by_project.any():\n",
    "        drop_index = file_infos.loc[~select_by_project, :].index[0]\n",
    "        drop_dup_indices.append(drop_index)\n",
    "    else:\n",
    "        raise ValueError(file_infos)\n",
    "\n",
    "found = found.drop(drop_dup_indices, axis=0, inplace=False)\n",
    "found.sort_values([\"sample\", \"datatype\", \"filename\"], inplace=True)\n",
    "found.reset_index(drop=True, inplace=True)\n",
    "found.drop([\"has_duplicated_accession\", \"annotated_project\"], axis=1, inplace=True)\n",
    "assert found[\"df_idx\"].nunique() == found.shape[0]\n",
    "\n",
    "output_table = PROJECT_BASE.joinpath(\n",
    "    \"annotations\", \"data_freezes\",\n",
    "    \"hgsvc3_assembly_data_sources.accessions.tsv\"\n",
    ")\n",
    "\n",
    "with open(output_table, \"w\") as dump:\n",
    "    _ = dump.write(f\"# {TODAY}\\n\")\n",
    "    found.to_csv(dump, sep=\"\\t\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
