{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f75e09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "%run \"../../00_project_config.ipynb\"\n",
    "%run \"../00_path_config.ipynb\"\n",
    "\n",
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle as pck\n",
    "import itertools as itt\n",
    "import hashlib as hl\n",
    "import numpy as np\n",
    "import collections as col\n",
    "\n",
    "input_table = PROJECT_BASE.joinpath(\n",
    "    \"annotations\", \"data_freezes\",\n",
    "    \"out-140.hgsvc3_data_sources.unpolished.tsv\"\n",
    ")\n",
    "\n",
    "HHU_GLOBUS = \"TMP:HHU:GLOBUS:/temp_data_sharing\"\n",
    "HHU_GLOBUS_ID = \"TMP:HHU:GLOBUS:UUID:5f441149-3339-4c4b-be1b-64c87d62a1e2\"\n",
    "\n",
    "output_table = PROJECT_BASE.joinpath(\n",
    "    \"annotations\", \"data_freezes\",\n",
    "    \"hgsvc3_assembly_data_sources.draft.tsv\"\n",
    ")\n",
    "\n",
    "def get_remote_prefix_header():\n",
    "    \n",
    "    header = \"\"\n",
    "    with open(input_table, \"r\") as table:\n",
    "        _ = table.readline()\n",
    "        for line in table:\n",
    "            if not line.startswith(\"#\"):\n",
    "                break\n",
    "            header += line.strip()\n",
    "            header += \"\\n\"\n",
    "    assert header\n",
    "    return header\n",
    "\n",
    "\n",
    "def print_select(df, selector):\n",
    "    \n",
    "    print(\"---\")\n",
    "    total_records = selector.sum()\n",
    "    runner = 0\n",
    "    for row in df.loc[selector].itertuples():\n",
    "        runner += 1\n",
    "        print(f\"{runner}/{total_records} [IDX:{row.Index}]\")\n",
    "        print(row)\n",
    "        print('---')\n",
    "    return\n",
    "\n",
    "\n",
    "df = pd.read_csv(input_table, sep=\"\\t\", comment=\"#\", header=0)\n",
    "df.drop([\"subfolder\", \"join_key\", \"remote_collection\"], axis=1, inplace=True)\n",
    "\n",
    "not_all = df[\"filename\"] != \"all\"\n",
    "\n",
    "# set source for HG02818 HiFi\n",
    "select_sample = df[\"sample\"] == \"HG02818\"\n",
    "select_dtype = df[\"datatype\"] == \"hifi\"\n",
    "select_files = (df[\"filename\"].str.contains(\"lib\")).values\n",
    "selector = not_all & select_sample & select_dtype & select_files\n",
    "df.loc[selector, \"accession\"] = \"PRJNA731524\"\n",
    "df.loc[selector, \"remote_path\"] = \"AWS:HPRC:working/HPRC_PLUS/HG02818/raw_data/PacBio_HiFi\"\n",
    "df.loc[selector, \"igsr_folder_exists\"] = \"no\"\n",
    "\n",
    "selector = not_all & select_sample & select_dtype & np.logical_not(select_files)\n",
    "df.loc[selector, \"accession\"] = \"PRJNA339722\"\n",
    "df.loc[selector, \"remote_path\"] = \"AWS:HPRC:working/HPRC_PLUS/HG02818/raw_data/PacBio_HiFi\"\n",
    "df.loc[selector, \"igsr_folder_exists\"] = \"no\"\n",
    "\n",
    "# set accession/source for NA24385\n",
    "select_sample = df[\"sample\"] == \"NA24385\"\n",
    "select_dtype = df[\"datatype\"] == \"hifi\"\n",
    "filesets = \"\"\"\n",
    "PRJNA731524/NA24385_m54329U_201103_231616.Q20.fastq.gz\n",
    "PRJNA731524/NA24385_m64076_201013_225902.Q20.fastq.gz\n",
    "PRJNA731524/NA24385_m64076_201016_191536.Q20.fastq.gz\n",
    "PRJNA731524/NA24385_m64076_210309_014547.hifi_reads.fastq.gz\n",
    "PRJNA731524/NA24385_m64076_210310_104300.hifi_reads.fastq.gz\n",
    "PRJNA586863/NA24385_m64011_190830_220126.Q20.fastq.gz\n",
    "PRJNA586863/NA24385_m64011_190901_095311.Q20.fastq.gz\n",
    "PRJNA586863/NA24385_m64012_190920_173625.Q20.fastq.gz\n",
    "PRJNA586863/NA24385_m64012_190921_234837.Q20.fastq.gz\n",
    "PRJNA813010/NA24385_m64004_210224_230828.hifi_reads.fastq.gz\n",
    "PRJNA813010/NA24385_m64014_210227_165255.hifi_reads.fastq.gz\n",
    "PRJNA813010/NA24385_m64015e_210223_010616.hifi_reads.fastq.gz\n",
    "PRJNA813010/NA24385_m64015e_210224_100310.hifi_reads.fastq.gz\n",
    "\"\"\"\n",
    "filesets = filesets.strip().split()\n",
    "filecollect = col.defaultdict(set)\n",
    "for entry in filesets:\n",
    "    acc, fn = entry.split(\"/\", 1)\n",
    "    filecollect[acc].add(fn)\n",
    "    \n",
    "for acc, fileset in filecollect.items():\n",
    "    select_files = df[\"filename\"].isin(fileset)\n",
    "    selector = not_all & select_sample & select_dtype & select_files\n",
    "    df.loc[selector, \"accession\"] = acc\n",
    "    df.loc[selector, \"igsr_folder_exists\"] = \"no\"\n",
    "    df.loc[selector, \"igsr_file_exists\"] = \"no\"\n",
    "    df.loc[selector, \"remote_path\"] = HHU_GLOBUS\n",
    "\n",
    "select_sample = df[\"sample\"] == \"NA24385\"\n",
    "select_dtype = df[\"datatype\"] == \"ont\"\n",
    "selector = not_all & select_sample & select_dtype\n",
    "df.loc[selector, \"accession\"] = \"unknown\"\n",
    "df.loc[selector, \"igsr_folder_exists\"] = \"no\"\n",
    "df.loc[selector, \"igsr_file_exists\"] = \"no\"\n",
    "df.loc[selector, \"remote_path\"] = HHU_GLOBUS\n",
    "\n",
    "\n",
    "# check for unexpected N/A\n",
    "selector = pd.isnull(df).any(axis=1)\n",
    "assert not selector.any()\n",
    "print_select(df, selector)\n",
    "\n",
    "column_sort_order = [\n",
    "    \"SIN\", \"hgsvc_sample_number\", \"sample\",\n",
    "    \"phase\", \"verkko_assembly_batch\",\n",
    "    \"population\", \"supergroup\", \"family\",\n",
    "    \"member\", \"sex\", \"is_child\",\n",
    "    \"datatype\", \"filename\", \"remote_path\", \"accession\",\n",
    "    \"igsr_folder_exists\", \"igsr_file_exists\",\n",
    "    \"cov_xfold_grt_0bp_at_3Gbp\", \"total_length_grt_0bp\",\n",
    "    \"total_num_grt_0bp\", \"length_N50_grt_0bp\", \"length_auN_grt_0bp\",\n",
    "    \"cov_xfold_grt_100kbp_at_3Gbp\", \"total_num_grt_100kbp\",\n",
    "    \"length_N50_grt_100kbp\", \"length_auN_grt_100kbp\", \"total_num_grt_1Mbp\"\n",
    "]\n",
    "\n",
    "sort_columns = set(column_sort_order)\n",
    "has_columns = set(df.columns.values)\n",
    "\n",
    "miss_in_sort = has_columns - sort_columns\n",
    "if miss_in_sort:\n",
    "    raise AssertionError(miss_in_sort)\n",
    "not_in_df = sort_columns - has_columns\n",
    "if not_in_df:\n",
    "    raise KeyError(not_in_df)\n",
    "\n",
    "\n",
    "df = df[column_sort_order]\n",
    "df.sort_values(\n",
    "    [\"hgsvc_sample_number\", \"datatype\", \"filename\"],\n",
    "    inplace=True, ascending=[True, True, False]\n",
    ")\n",
    "\n",
    "\n",
    "def get_sample_count_header(df):\n",
    "    \n",
    "    samples = df.drop_duplicates(\"SIN\", inplace=False)[\"verkko_assembly_batch\"].value_counts()\n",
    "    total_samples = samples.sum()\n",
    "    \n",
    "    header = f\"# Total HGSVC3 samples: {total_samples}\\n\"\n",
    "    for batch, num in samples.items():\n",
    "        header += f\"# Verkko batch {batch}: {num} samples\\n\"\n",
    "        \n",
    "    return header\n",
    "    \n",
    "source_header = get_remote_prefix_header()\n",
    "verkko_header = get_sample_count_header(df)\n",
    "with open(output_table, \"w\") as dump:\n",
    "    _ = dump.write(f\"# {TODAY}\\n\")\n",
    "    _ = dump.write(source_header)\n",
    "    _ = dump.write(f\"# {HHU_GLOBUS_ID}\\n\")\n",
    "    _ = dump.write(verkko_header)\n",
    "    df.to_csv(dump, sep=\"\\t\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
