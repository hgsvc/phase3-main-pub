{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a796116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "%cd -q \"/home/ebertp/work/code/cubi/project-run-hgsvc-hybrid-assemblies/notebooks\"\n",
    "_PROJECT_CONFIG_NB = str(pl.Path(\"00_project_config.ipynb\").resolve(strict=True))\n",
    "\n",
    "%run $_PROJECT_CONFIG_NB\n",
    "\n",
    "_MYNAME=\"asm-stats-summary-table\"\n",
    "_NBSTAMP=get_nb_stamp(_MYNAME)\n",
    "\n",
    "assembler = \"verkko\"\n",
    "assembler_versions = {\n",
    "    \"verkko\": \"Verkko v1.4.1\",\n",
    "    \"hifiasm\": \"hifiasm v0.19.5\"\n",
    "}\n",
    "\n",
    "input_path = PROJECT_DATA_ROOT.joinpath(\n",
    "    f\"2023_assm_stats/{assembler}/hgsvc3/contig_stats\"\n",
    ")\n",
    "\n",
    "output_table_sheet = PROJECT_BASE.joinpath(\n",
    "    \"annotations\", \"autogen\", f\"{assembler}_assemblies.hgsvc3.tsv\"\n",
    ")\n",
    "\n",
    "merged = []\n",
    "for tsv_file in input_path.glob(\"*.summary.tsv\"):\n",
    "    name_parts = tsv_file.name.split(\".\")\n",
    "    sample = name_parts[0]\n",
    "    sample_num = int(HGSVC_SAMPLES.loc[HGSVC_SAMPLES[\"sample\"] == sample, \"order_num\"].values[0])\n",
    "    sample_batch = int(HGSVC_SAMPLES.loc[HGSVC_SAMPLES[\"sample\"] == sample, \"batch_num\"].values[0])\n",
    "    asm_unit = name_parts[2]\n",
    "    df = pd.read_csv(tsv_file, sep=\"\\t\", header=0)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame(\n",
    "            [\n",
    "                [\"all\", \"total_length_grt_0bp\", 0, sample, sample_num, sample_batch, asm_unit],\n",
    "                [\"all\", \"total_num_grt_0bp\", 0, sample, sample_num, sample_batch, asm_unit]\n",
    "            ],\n",
    "            columns=[\"source\", \"statistic\", \"value\", \"sample\", \"sample_num\", \"verkko_batch\", \"sequence\"]\n",
    "        )\n",
    "    else:\n",
    "        df[\"sample\"] = sample\n",
    "        df[\"sample_num\"] = sample_num\n",
    "        df[\"verkko_batch\"] = sample_batch\n",
    "        df[\"sequence\"] = asm_unit\n",
    "    merged.append(df)\n",
    "    \n",
    "merged = pd.concat(merged, axis=0, ignore_index=False)\n",
    "merged.drop(\"source\", axis=1, inplace=True)\n",
    "row_index = pd.MultiIndex.from_tuples(\n",
    "    sorted(set([(row.sample, int(row.sample_num), int(row.verkko_batch)) for row in merged.itertuples()])),\n",
    "    names=[\"sample\", \"sample_num\", \"verkko_batch\"]\n",
    ")\n",
    "column_index = pd.Index(\n",
    "    [(seq, stat) for (seq, stat), _ in merged.groupby([\"sequence\", \"statistic\"])],\n",
    "    tupleize_cols=True, name=(\"sequence\", \"statistic\"))\n",
    "\n",
    "pivot = pd.DataFrame([], index=row_index, columns=column_index)\n",
    "for row in merged.itertuples():\n",
    "    pivot.loc[(row.sample, row.sample_num), (row.sequence, row.statistic)] = row.value\n",
    "pivot = pivot.fillna(0, inplace=False).infer_objects(copy=False)\n",
    "\n",
    "sort_seq = {\n",
    "    'asm-hap1': 0,\n",
    "    'asm-hap2': 1,\n",
    "    'asm-unassigned': 2,\n",
    "    'asm-rdna': 3,\n",
    "    'asm-disconnected': 4,\n",
    "    'contaminants': 5\n",
    "}\n",
    "\n",
    "if assembler == \"verkko\":\n",
    "\n",
    "    aun = \"length_auN_grt_0bp\"\n",
    "    length = \"total_length_grt_0bp\"\n",
    "       \n",
    "    for other_seq in [\"asm-unassigned\", \"asm-disconnected\"]:\n",
    "    \n",
    "        other_length = pivot.xs((other_seq, length), level=[\"sequence\", \"statistic\"], axis=1)\n",
    "        hap1_length = pivot.xs((\"asm-hap1\", length), level=[\"sequence\", \"statistic\"], axis=1).values\n",
    "        hap2_length = pivot.xs((\"asm-hap2\", length), level=[\"sequence\", \"statistic\"], axis=1).values\n",
    "        dip_length = hap1_length + hap2_length\n",
    "        pct_length = ((other_length.values / dip_length) * 100).round(3)\n",
    "        pct_length = pd.DataFrame(\n",
    "            pct_length,\n",
    "            index=pivot.index,\n",
    "            columns=pd.MultiIndex.from_tuples(\n",
    "                [(other_seq, \"pct_dip_length_grt_0bp\")],\n",
    "                names=[\"sequence\", \"statistic\"]\n",
    "            )\n",
    "        )\n",
    "        pivot = pivot.merge(pct_length, left_index=True, right_index=True)\n",
    "pivot.sort_index(axis=0, level=\"sample_num\", inplace=True)\n",
    "\n",
    "\n",
    "def sort_column_index(column_index):\n",
    "    \n",
    "    stats_values = column_index.get_level_values(\"statistic\")\n",
    "    \n",
    "    get_seq_context = re.compile(\"(0bp|[0-9]+[kM]bp)\")\n",
    "    sort_stat = {}\n",
    "    for entry in set(stats_values):\n",
    "        mobj = get_seq_context.search(entry)\n",
    "        if mobj is None:\n",
    "            raise ValueError(entry)\n",
    "        seq_context = mobj.group(0)\n",
    "        if \"kbp\" in seq_context:\n",
    "            factor = 1e3\n",
    "            order_num = int(int(seq_context.strip(\"kbp\")) * factor)\n",
    "        elif \"Mbp\" in seq_context:\n",
    "            factor = 1e6\n",
    "            order_num = int(int(seq_context.strip(\"Mbp\")) * factor)\n",
    "        else:\n",
    "            order_num = 0\n",
    "        sort_stat[entry] = order_num\n",
    "    \n",
    "    index_tuples = column_index.to_flat_index()\n",
    "    \n",
    "    sorted_tuples = sorted(\n",
    "        [(sort_seq[t[0]], sort_stat[t[1]], t) for t in index_tuples]\n",
    "    )\n",
    "    \n",
    "    sorted_mindex = pd.MultiIndex.from_tuples(\n",
    "        [t[2] for t in sorted_tuples],\n",
    "        names=[\"sequence\", \"statistic\"]\n",
    "    )\n",
    "    \n",
    "    return sorted_mindex\n",
    "\n",
    "sorted_mindex_cols = sort_column_index(pivot.columns)\n",
    "\n",
    "pivot = pivot.loc[:, sorted_mindex_cols]\n",
    "\n",
    "with open(output_table_sheet, \"w\") as table_out:\n",
    "    _ = table_out.write(\"# AUTOGEN TABLE - DO NOT EDIT\\n\")\n",
    "    _ = table_out.write(f\"# {_NBSTAMP}\\n\")\n",
    "    _ = table_out.write(f\"# {assembler_versions[assembler]} HGSVC3 phased assemblies\\n\")\n",
    "    _ = table_out.write(f\"# {pivot.index.get_level_values('sample').nunique()} samples\\n\")\n",
    "    pivot.to_csv(table_out, sep=\"\\t\", index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
