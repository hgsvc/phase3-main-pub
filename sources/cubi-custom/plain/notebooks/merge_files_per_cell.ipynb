{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94fa505f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HiFi  22.71897417145091\n",
      "ONT  23.479925036283827\n",
      "(474, 5)\n",
      "(275, 4)\n",
      "              sample  cardinality    size_byte   \n",
      "223  HG00096-hifi-G1            1  27056024726  \\\n",
      "224  HG00096-hifi-G2            1  27894899294   \n",
      "225  HG00096-hifi-G3            1  28440271135   \n",
      "191   HG00096-ont-G1            2  30962974958   \n",
      "192   HG00096-ont-G2            1  31844157844   \n",
      "182  HG00171-hifi-G1            1  29252258578   \n",
      "183  HG00171-hifi-G2            1  30387867787   \n",
      "184  HG00171-hifi-G3            1  30608884961   \n",
      "149   HG00171-ont-G1            4  13708644482   \n",
      "150   HG00171-ont-G2            1  13052043593   \n",
      "151   HG00171-ont-G3            1  15349687373   \n",
      "152   HG00171-ont-G4            1  15767547329   \n",
      "153   HG00171-ont-G5            1  16176464864   \n",
      "154   HG00171-ont-G6            1  18188089102   \n",
      "155   HG00171-ont-G7            1  20460243472   \n",
      "156   HG00171-ont-G8            1  22892175968   \n",
      "24   HG00512-hifi-G1            2  23097046267   \n",
      "25   HG00512-hifi-G2            1  14112189974   \n",
      "26   HG00512-hifi-G3            1  15989512583   \n",
      "27   HG00512-hifi-G4            1  16417539654   \n",
      "\n",
      "                                                 input  \n",
      "223  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "224  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "225  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "191  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "192  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "182  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "183  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "184  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "149  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "150  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "151  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "152  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "153  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "154  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "155  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "156  /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "24   /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "25   /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "26   /gpfs/project/projects/medbioinf/data/00_RESTR...  \n",
      "27   /gpfs/project/projects/medbioinf/data/00_RESTR...  \n"
     ]
    }
   ],
   "source": [
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "import pickle as pck\n",
    "import re as re\n",
    "import collections as col\n",
    "import os\n",
    "\n",
    "mount = pl.Path(\"/mounts/hilbert/project\")\n",
    "remote = pl.Path(\"/gpfs/project\")\n",
    "\n",
    "sample_folder = pl.Path(\"projects/medbioinf/data/00_RESTRUCTURE/sample-centric\")\n",
    "\n",
    "data_root = pl.Path(\"projects/medbioinf/data/00_RESTRUCTURE\")\n",
    "\n",
    "cache_mapping = pl.Path(\".\").joinpath(\".cache\", \"file_cell_map.pck\")\n",
    "cache_mapping.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "hifi_cell = re.compile(\"(m[0-9a-z_U]{16,24}|[ABCDEFSPL0-9_\\-]{22,28})\")\n",
    "ont_cell = re.compile(\"(P|G)[A-Z0-9_\\-]{8,16}\")\n",
    "\n",
    "contains_date = re.compile(\"20[0-9]{2}[0-9]{4}\")\n",
    "contains_sample = re.compile(\"(HG|NA|GM)[0-9]{5}\")\n",
    "\n",
    "cells = re.compile(f\"((?P<hifi>{hifi_cell})|(?P<ont>{ont_cell}))\")\n",
    "\n",
    "samples_out = pl.Path(\"../samples/check_kmer.tsv\")\n",
    "\n",
    "if cache_mapping.is_file():\n",
    "    with open(cache_mapping, \"rb\") as dump:\n",
    "        mapping = pck.load(dump)\n",
    "else:\n",
    "    mapping = col.defaultdict(set)\n",
    "    for fofn in mount.joinpath(sample_folder).glob(\"**/*.fofn\"):\n",
    "        if \"strandseq\" in fofn.name:\n",
    "            continue\n",
    "        with open(fofn, \"r\") as listing:\n",
    "            sample = fofn.name.split(\"_\")[0]\n",
    "            for line in listing:\n",
    "                is_ont = False\n",
    "                is_hifi = False\n",
    "                if not line.strip() or line.startswith(\"#\"):\n",
    "                    continue\n",
    "                fofn_name = fofn.name\n",
    "                \n",
    "                file_rel_path = pl.Path(line.strip())\n",
    "                file_name = file_rel_path.name\n",
    "                file_path = mount.joinpath(data_root, file_rel_path)\n",
    "                remote_path = remote.joinpath(data_root, file_rel_path)\n",
    "                if \"nanopore\" in str(remote_path):\n",
    "                    is_ont = True\n",
    "                elif \"pacbio_hifi\" in str(remote_path):\n",
    "                    is_hifi = True\n",
    "                else:\n",
    "                    raise\n",
    "                file_size = os.stat(file_path).st_size\n",
    "                stripped_name = file_name\n",
    "                \n",
    "                mobj = contains_date.search(stripped_name)\n",
    "                if mobj is not None:\n",
    "                    stripped_name = stripped_name.replace(mobj.group(0), \"\")\n",
    "                mobj = contains_sample.search(stripped_name)\n",
    "                if mobj is not None:\n",
    "                    stripped_name = stripped_name.replace(mobj.group(0), \"\")\n",
    "                \n",
    "                if is_hifi:\n",
    "                    mobj = hifi_cell.search(stripped_name)\n",
    "                elif is_ont:\n",
    "                    mobj = ont_cell.search(stripped_name)\n",
    "                else:\n",
    "                    raise\n",
    "                if mobj is None:\n",
    "                    raise ValueError(f\"None: {file_name}\")\n",
    "                else:\n",
    "                    cell_id = mobj.group(0)\n",
    "                    cell_id = cell_id.strip(\"-_.\")\n",
    "                    mapping[(\"size\", file_name)] = file_size\n",
    "                    mapping[(\"remote\", file_name)] = remote_path\n",
    "                    read_type = \"hifi\" if is_hifi else \"ont\"\n",
    "                    mapping[(read_type, cell_id, fofn_name)].add(file_name)\n",
    "                    mapping[(read_type, file_name, fofn_name)].add(cell_id)\n",
    "                    \n",
    "    with open(cache_mapping, \"wb\") as dump:\n",
    "        pck.dump(mapping, dump)\n",
    "\n",
    "\n",
    "def to_gb(size_in_byte):\n",
    "    return round(size_in_byte / 1e9, 1)\n",
    "\n",
    "\n",
    "def determine_mean_file_size(data_files, read_type):\n",
    "    \n",
    "    total_size = 0\n",
    "    total_files = 0\n",
    "    for (smp, rtype), files in data_files.items():\n",
    "        if rtype != read_type:\n",
    "            continue\n",
    "        total_size += sum(t[0] for t in files)\n",
    "        total_files += len(files)\n",
    "    return total_size / total_files\n",
    "\n",
    "\n",
    "def group_files(data_files, mean_size, read_type):\n",
    "    grouping = []\n",
    "    for (smp, rtype), files in data_files.items():\n",
    "        sample_grouping = []\n",
    "        if rtype != read_type:\n",
    "            continue\n",
    "        if len(files) < 3:\n",
    "            gnum = 1\n",
    "            for size, file_name, remote_path in sorted(files, reverse=True):\n",
    "                group_name = f\"{smp}-{read_type}-G{gnum}\"\n",
    "                group_size = size\n",
    "                group_files = str(remote_path)\n",
    "                sample_grouping.append((group_name, 1, group_size, group_files))\n",
    "                gnum += 1\n",
    "        else:\n",
    "            gnum = 1\n",
    "            gsize = 0\n",
    "            gcard = 0\n",
    "            gfiles = []\n",
    "            sample_grouping = []\n",
    "            assert len(set(files)) == len(files)\n",
    "            for size, file_name, remote_path in sorted(files, reverse=False):\n",
    "                gsize += size\n",
    "                gcard += 1\n",
    "                gfiles.append(str(remote_path))\n",
    "                if gsize > mean_size:\n",
    "                    group_name = f\"{smp}-{read_type}-G{gnum}\"\n",
    "                    group_files = \",\".join(gfiles)\n",
    "                    sample_grouping.append((group_name, gcard, gsize, group_files))\n",
    "                    gnum += 1\n",
    "                    gsize = 0\n",
    "                    gcard = 0\n",
    "                    gfiles = []\n",
    "            if gfiles:\n",
    "                group_name = f\"{smp}-{read_type}-G{gnum}\"\n",
    "                group_files = ','.join(sorted(gfiles))\n",
    "                assert gsize > mean_size, gsize\n",
    "                sample_grouping.append((group_name, gcard, gsize, group_files))\n",
    "        grouping.extend(sample_grouping)\n",
    "\n",
    "    df = pd.DataFrame.from_records(\n",
    "        grouping,\n",
    "        columns=[\"sample\", \"cardinality\", \"size_byte\", \"input\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "group_by_sample = col.defaultdict(list)\n",
    "for k,v in mapping.items():\n",
    "    if k[0] in [\"size\", \"remote\"]:\n",
    "        continue\n",
    "    read_type, cell_or_file, fofn_name = k\n",
    "    sample = fofn_name.split(\"_\")[0]\n",
    "    if cell_or_file.endswith(\".fastq.gz\"):\n",
    "        continue\n",
    "    for file_name in v:\n",
    "        file_size = mapping[(\"size\", file_name)]\n",
    "        remote_path = mapping[(\"remote\", file_name)]\n",
    "        group_by_sample[(sample, read_type)].append((file_size, file_name, remote_path))\n",
    "        \n",
    "mean_hifi_size = determine_mean_file_size(group_by_sample, \"hifi\")\n",
    "print(\"HiFi \", mean_hifi_size / 1e9)\n",
    "mean_ont_size = determine_mean_file_size(group_by_sample, \"ont\")\n",
    "print(\"ONT \", mean_ont_size / 1e9)\n",
    "\n",
    "hifi_groups = group_files(group_by_sample, int(mean_hifi_size * 0.5), \"hifi\")\n",
    "ont_groups = group_files(group_by_sample, int(mean_ont_size * 0.5), \"ont\")\n",
    "file_groups = pd.concat([hifi_groups, ont_groups], axis=0, ignore_index=False)\n",
    "\n",
    "# preparing a subset of the samples to establish a baseline:\n",
    "# select all samples that have a |group| > 1\n",
    "samples = file_groups.loc[file_groups[\"cardinality\"] > 1, \"sample\"]\n",
    "samples = set(s.split(\"-\")[0] for s in samples)\n",
    "\n",
    "def select_sample(sample):\n",
    "    return any(sample.startswith(s) for s in samples)\n",
    "\n",
    "file_groups[\"select\"] = file_groups[\"sample\"].apply(select_sample)\n",
    "print(file_groups.shape)\n",
    "subset = file_groups.loc[file_groups[\"select\"], :].copy()\n",
    "subset.drop([\"select\"], axis=1, inplace=True)\n",
    "subset.sort_values([\"sample\", \"cardinality\"], inplace=True)\n",
    "subset.to_csv(samples_out, header=True, index=False, sep=\"\\t\")\n",
    "print(subset.shape)\n",
    "\n",
    "print(subset.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
