#!/usr/bin/env python3

# Parse water output and build histogram of insertion/deletion lengths.

import argparse
import csv
import gzip
import os
import re    
import sys

# increase CSV max field size
csv.field_size_limit(256 * 1024 * 1024)

def log_info(msg):
    sys.stderr.write("INFO - " + msg + "\n")
    sys.stderr.flush()

def log_fatal(msg):
    sys.stderr.write("FATAL - " + msg + "\n")
    sys.stderr.flush()
    sys.exit(1)

ME_LENGTHS = {
    'ALU': 281,
    'SVA': 1316,
    'LINE1': 6019
}
    
# ------------------------------------------------------
# index_fasta()
# ------------------------------------------------------

# read indel metadata from file generated by extract_(insertion|deletion)_seqs.py

def index_fasta(ffile):
    index = {}
    ns = 0
    
    with open(ffile, 'rt') as fh:
        for line in fh:
            m = re.match(r'^> (\S+) (\S+) (ID=.*)$', line)
            if m:
                ns += 1
                index[m.group(1)] = m.group(3)
    print("indexed " + str(ns) + " sequence(s) from " + ffile)
    return index
                
# ------------------------------------------------------
# parse_water()
# ------------------------------------------------------

def parse_water(wfile, min_pctid, min_pctcov, ff_ind):
    n_lines = 0
    n_alignments = 0
    n_above_min_pctid_and_cov = 0
    indel_lengths = {}
    alignment = None

    def process_alignment(al):
        nonlocal n_alignments
        nonlocal n_above_min_pctid_and_cov
        
        if al is None:
            return

        n_alignments += 1

        me_length = ME_LENGTHS[al['ME']]
        min_bp = int(me_length * (min_pctcov / 100.0))

        if al['pct_id'] >= min_pctid and al['matches'] >= min_bp:
            n_above_min_pctid_and_cov += 1
            if al['matches'] in indel_lengths:
                indel_lengths[al['matches']] += 1
            else:
                indel_lengths[al['matches']] = 1

            v_info = ff_ind[al['variant_name']]
            # multiple alleles?
            m = re.match(r'.*QUERY_STRAND=([^;]+);.*', v_info)
            qs = m.group(1)
            hz_flag = 'HZ' if re.search(r',', qs) else '  ';
                
            print(al['variant_name'] + " " + str(al['matches']) + "/" + str(al['length']) + " (" + str(al['pct_id']) + "%) " + hz_flag + " " + v_info)
                
    with gzip.open(wfile, 'rt') as fh:
        for line in fh:
            n_lines += 1
            if re.match(r'^\# Aligned_sequences: 2.*$', line):
                if alignment is not None:
                    process_alignment(alignment)
                alignment = {}
#                print("n_lines=" + str(n_lines))
            else:
                m = re.match(r'^# 1: (\S+).*', line)
                if m:
                    alignment['ME'] = m.group(1)
                    
                m = re.match(r'^# 2: (\S+-(INS|DEL)-(\d+))', line)
                if m:
                    alignment['variant_name'] = m.group(1)
                    alignment['variant_type'] = m.group(2)
                    alignment['variant_len'] = int(m.group(3))
                    if alignment['variant_len'] < 50:
                        print("lnum=" + str(n_lines))

                m = re.match(r'^# Identity:\s+(\d+)\/(\d+) \((\s*[\d\.]+)%\)', line)
                if m:
                    alignment['matches'] = int(m.group(1))
                    alignment['length'] = int(m.group(2))
                    alignment['pct_id'] = float(m.group(3))

    process_alignment(alignment)
    print("n_lines=" + str(n_lines))
    print("n_alignments=" + str(n_alignments))
    print("n >= " + str(min_pctid) + "% identity and >= " + str(min_pctcov) + "% coverage = " + str(n_above_min_pctid_and_cov))
    print("histogram (n_identical_bp : count)")
    for len in sorted(indel_lengths):
        count = indel_lengths[len]
        print(str(len) + " : " + str(count))
    
# ------------------------------------------------------
# main()
# ------------------------------------------------------

def main():

    # input
    parser = argparse.ArgumentParser(description='Parse and summarize water output.')
    parser.add_argument('--fasta', required=True, help='Path to FASTA sequence file used as input to water.')
    parser.add_argument('--water', required=True, help='Path to water output file.')
    parser.add_argument('--min_pctid', required=False, type=int, default=1, help='Minimum percent identity of match.')
    parser.add_argument('--min_pctcov', required=False, type=int, default=1, help='Minimum percent coverage of match.')
    args = parser.parse_args()
    ff_ind = index_fasta(args.fasta)
    parse_water(args.water, args.min_pctid, args.min_pctcov, ff_ind)
        
if __name__ == '__main__':
    main()



